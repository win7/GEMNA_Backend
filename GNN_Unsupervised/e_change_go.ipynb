{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from utils.utils_go import *\n",
    "\n",
    "# %load_ext autotime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp:\t\t exp10\n",
      "Methods:\t ['vgae-base']\n",
      "Data variations: ['str']\n",
      "Control:\t HN\n",
      "Threshold log2:\t 0\n",
      "Alpha:\t\t 0.05\n",
      "Subgroups id:\t {'HN': ['1', '2'], 'HV': ['1', '2']}\n",
      "Groups:\t\t [['HN', 'HV']]\n"
     ]
    }
   ],
   "source": [
    "file = open(\"exp.json\")\n",
    "experiment = json.load(file)\n",
    "exp_num = experiment[\"exp\"]\n",
    "\n",
    "file = open(\"output/{}/parameters.json\".format(exp_num))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "control = params[\"control\"]\n",
    "print(\"Control:\\t\", control)\n",
    "\n",
    "threshold_log2 = params[\"threshold_log2\"]\n",
    "print(\"Threshold log2:\\t\", threshold_log2)\n",
    "\n",
    "alpha = params[\"alpha\"]\n",
    "print(\"Alpha:\\t\\t\", alpha)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/miniconda3/envs/metanet_3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/home/ealvarez/miniconda3/envs/metanet_3.10/lib/python3.10/site-packages/pandas/core/arraylike.py:396: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# read raw data\n",
    "df_join_raw = pd.read_csv(\"input/{}_raw.csv\".format(exp), index_col=0)\n",
    "df_join_raw.head()\n",
    "list_details = []\n",
    "\n",
    "for method in methods: # change\n",
    "    for data_variation in data_variations: # change\n",
    "        for group in groups: # change\n",
    "            # read edges\n",
    "            list_graphs = []\n",
    "            for k in range(len(group)):\n",
    "                df_edges = pd.read_csv(\"output/{}/common_edges/common_edges_{}_{}_{}.csv\".format(exp, method, group[k], data_variation))\n",
    "                sort_df_edges(df_edges)\n",
    "                df_edges.rename(columns={\"weight\": \"weight{}\".format(k + 1)}, inplace=True)\n",
    "                G = nx.from_pandas_edgelist(df_edges, edge_attr=[\"weight{}\".format(k + 1)])\n",
    "                list_graphs.append(G)\n",
    "                \n",
    "            # compose\n",
    "            R = nx.compose(list_graphs[0], list_graphs[1])\n",
    "            nx.set_edge_attributes(R, {(u, v): {\"label\": get_label(ed, th=0.8)} for u, v, ed in R.edges.data()})\n",
    "            # print(R.number_of_nodes(), R.number_of_edges())\n",
    "\n",
    "            df_change = nx.to_pandas_edgelist(R)\n",
    "            df_change = df_change[[\"source\", \"target\", \"weight1\", \"weight2\", \"label\"]]\n",
    "            df_change.to_csv(\"output/{}/changes/changes_edges_compose_{}_{}_{}_{}.csv\".format(exp, method, group[0], group[1], data_variation), index=False)\n",
    "\n",
    "            # differences between correlations\n",
    "            df_change.insert(3, \"N1\", [len(df_join_raw.filter(like=group[0]).columns)] * len(df_change))\n",
    "            df_change.insert(5, \"N2\", [len(df_join_raw.filter(like=group[1]).columns)] * len(df_change))\n",
    "\n",
    "            # differences between correlations\n",
    "            n1 = len(df_join_raw.filter(like=group[0]).columns) # len(df_change) - df_change[\"weight1\"].isna().sum() # len(df_change)\n",
    "            n2 = len(df_join_raw.filter(like=group[1]).columns) # len(df_change) - df_change[\"weight2\"].isna().sum() # len(df_change)\n",
    "            z1 = fisher_transform(df_change[\"weight1\"])\n",
    "            z2 = fisher_transform(df_change[\"weight2\"])\n",
    "            sezdiff = np.sqrt(1 / (n1 - 3) + 1 / (n2 - 3))\n",
    "            diff = z1 - z2\n",
    "            ztest = diff / sezdiff\n",
    "            p_value = 2 * (1 - scipy.stats.norm.cdf(np.abs(ztest), loc=0, scale=1))\n",
    "            df_change[\"p-value\"] = p_value\n",
    "\n",
    "            # get sigtnificant\n",
    "            list_significant = []\n",
    "            for row in df_change.itertuples():\n",
    "                # print(row[3], row[5], row[8])\n",
    "                if row[8] < alpha:\n",
    "                    list_significant.append(\"*\")\n",
    "                elif row[8] >= alpha:\n",
    "                    list_significant.append(\"\")\n",
    "                elif np.isnan(row[3]) or np.isnan(row[5]):\n",
    "                    list_significant.append(\"*\")\n",
    "                else:\n",
    "                    list_significant.append(\"x\")\n",
    "            df_change[\"significant\"] = list_significant\n",
    "            # count_values(df_change[\"significant\"])\n",
    "\n",
    "            \"\"\" try:\n",
    "                x = df_change[\"p-value\"]\n",
    "                hist(x, th=alpha)\n",
    "            except:\n",
    "                pass \"\"\"\n",
    "\n",
    "            # filter by significant\n",
    "            # df_change_filter = df_change[df_change[\"p-value\"] < alpha]\n",
    "            df_change_filter1 = df_change[df_change[\"significant\"] != \"x\"].copy()\n",
    "            df_change_filter1.to_csv(\"output/{}/changes/changes_edges_significant_{}_{}_{}_{}.csv\".format(exp, method, group[0], group[1], data_variation), index=False)\n",
    "\n",
    "            # common subgraph\n",
    "            G = nx.from_pandas_edgelist(df_change_filter1.iloc[:, [0, 1]])\n",
    "\n",
    "            # filter raw data by common nodes\n",
    "            nodes_common = sorted(list(G.nodes()))\n",
    "            df_join_raw_filter = df_join_raw.loc[nodes_common]\n",
    "\n",
    "            # filter by log2\n",
    "            df_join_raw_filter_log2 = np.log2(df_join_raw_filter.filter(like=group[1]).mean(axis=1) / df_join_raw_filter.filter(like=group[0]).mean(axis=1))\n",
    "            df_join_raw_filter_log2 = df_join_raw_filter_log2.to_frame()\n",
    "            df_join_raw_filter_log2.columns = [\"log2\"]\n",
    "\n",
    "            df_join_raw_filter_log2_filter = df_join_raw_filter_log2[((df_join_raw_filter_log2[\"log2\"] > threshold_log2) | (df_join_raw_filter_log2[\"log2\"] < -threshold_log2))]\n",
    "            nodes_log2 = list(df_join_raw_filter_log2_filter.index)\n",
    "\n",
    "            log2 = []\n",
    "            for row in df_change_filter1.itertuples():\n",
    "                if row[1] in nodes_log2 and row[2] in nodes_log2:\n",
    "                    log2.append(True)\n",
    "                else:\n",
    "                    log2.append(False)\n",
    "            df_change_filter1[\"log2\"] = log2\n",
    "\n",
    "            df_change_filter2 = df_change_filter1[df_change_filter1[\"log2\"] == True]\n",
    "            df_change_filter2 = df_change_filter2.iloc[:, :-1]\n",
    "\n",
    "            # mapping aligment ID to average mz\n",
    "            df_change_filter = df_change_filter2.copy() # df_change_filter1, df_change_filter2\n",
    "\n",
    "            dict_aux = df_join_raw.iloc[:, :2].to_dict(orient=\"dict\")\n",
    "            dict_mz = dict_aux[\"Average Mz\"]\n",
    "            dict_mz = {key: value for key, value in dict_mz.items()}\n",
    "            dict_metabolite = dict_aux[\"Metabolite name\"]\n",
    "            dict_metabolite = {key: value for key, value in dict_metabolite.items()}\n",
    "\n",
    "            # mapping\n",
    "            df_change_filter[\"source1\"] = df_change_filter[\"source\"].map(dict_mz)\n",
    "            df_change_filter[\"target1\"] = df_change_filter[\"target\"].map(dict_mz)\n",
    "            df_change_filter[\"source2\"] = df_change_filter[\"source\"].map(dict_metabolite)\n",
    "            df_change_filter[\"target2\"] = df_change_filter[\"target\"].map(dict_metabolite)\n",
    "            df_change_filter.to_csv(\"output/{}/changes/changes_edges_log2_{}_{}_{}_{}.csv\".format(exp, method, group[0], group[1], data_variation), index=False)\n",
    "            \n",
    "            G = nx.from_pandas_edgelist(df_change_filter, \"source\", \"target\", edge_attr=\"weight1\")\n",
    "            list_details.append([method, \"-\".join(group), data_variation, G.number_of_nodes(), G.number_of_edges(), nx.density(G)])\n",
    "\n",
    "df_details = pd.DataFrame(list_details, columns=[\"Method\", \"Group\", \"Data var.\", \"Num. nodes\", \"Num. edges\", \"Density\"])\n",
    "df_details.to_csv(\"output/{}/changes/summary.csv\".format(exp), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
