{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import dgl\n",
    "\n",
    "import model\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import CiteseerGraphDataset, CoraGraphDataset, PubmedGraphDataset\n",
    "# from input_data import load_data\n",
    "\n",
    "import torch\n",
    "from dgl.data import DGLDataset\n",
    "\n",
    "from preprocess import (\n",
    "    mask_test_edges,\n",
    "    mask_test_edges_dgl,\n",
    "    preprocess_graph,\n",
    "    sparse_to_tuple,\n",
    ")\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 147 µs (started: 2023-10-01 22:44:28 -05:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 437 ms (started: 2023-10-01 22:44:28 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 211 µs (started: 2023-10-01 22:44:28 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(42)\n",
    "# np.random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/catolica/Project/Python/GNN_Unsupervised\n",
      "Exp:\t\t exp53\n",
      "Method:\t\t vgae\n",
      "Dimension:\t 3\n",
      "Groups id:\t ['pck1', 'zwf1', 'WT']\n",
      "Subgroups id:\t {'pck1': ['1', '2', '3'], 'zwf1': ['1', '2'], 'WT': ['1', '2', '3', '4', '5']}\n",
      "Option:\t\t dyn\n",
      "Options:\t ['', 'str', 'dyn']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' if option:\\n    for group in groups_id:\\n        subgroups_id[group] = [option]\\n    print(\"Subgroups id:\\t\", subgroups_id) '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 80.3 ms (started: 2023-10-01 22:44:28 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "dir = os.path.dirname(os.getcwd())\n",
    "print(dir)\n",
    "\n",
    "# opening JSON file\n",
    "file = open(\"{}/parameters.json\".format(dir))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "method = \"vgae\"\n",
    "print(\"Method:\\t\\t\", method)\n",
    "\n",
    "dimension = params[\"dimension\"]\n",
    "print(\"Dimension:\\t\", dimension)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "option = params[\"option\"]\n",
    "print(\"Option:\\t\\t\", option)\n",
    "\n",
    "options = params[\"options\"]\n",
    "print(\"Options:\\t\", options)\n",
    "\n",
    "\"\"\" if option:\n",
    "    for group in groups_id:\n",
    "        subgroups_id[group] = [option]\n",
    "    print(\"Subgroups id:\\t\", subgroups_id) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 56.6 ms (started: 2023-10-01 22:44:28 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# custom dataset\n",
    "\n",
    "class CustomDataset(DGLDataset):\n",
    "    def __init__(self, name, nodes_data, edges_data):\n",
    "        self.dir = dir\n",
    "        self.nodes_data = nodes_data\n",
    "        self.edges_data = edges_data\n",
    "        super().__init__(name=name)\n",
    "       \n",
    "    def process(self):\n",
    "        node_features = torch.from_numpy(self.nodes_data.to_numpy())\n",
    "        # node_features = torch.from_numpy(np.log10(self.nodes_data[\"degree\"].to_numpy()))\n",
    "        node_features = node_features.to(torch.float32)\n",
    "        # node_features = torch.reshape(node_features, (-1, 1))\n",
    "\n",
    "        # node_labels = torch.from_numpy(self.nodes_data[\"id\"].to_numpy())\n",
    "        # node_labels = node_labels.to(torch.float32)\n",
    "\n",
    "        edge_features = torch.from_numpy(self.edges_data[\"weight\"].to_numpy())\n",
    "        edges_src = torch.from_numpy(self.edges_data[\"source\"].to_numpy())\n",
    "        edges_dst = torch.from_numpy(self.edges_data[\"target\"].to_numpy())\n",
    "\n",
    "        self.graph = dgl.graph(\n",
    "            (edges_src, edges_dst), num_nodes=self.nodes_data.shape[0]\n",
    "        )\n",
    "        self.graph.ndata[\"feat\"] = node_features\n",
    "        # self.graph.ndata[\"label\"] = node_labels\n",
    "        self.graph.edata[\"weight\"] = edge_features\n",
    "\n",
    "        # If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "        n_nodes = self.nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train : n_train + n_val] = True\n",
    "        test_mask[n_train + n_val :] = True\n",
    "        self.graph.ndata[\"train_mask\"] = train_mask\n",
    "        self.graph.ndata[\"val_mask\"] = val_mask\n",
    "        self.graph.ndata[\"test_mask\"] = test_mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=120, num_edges=6937,\n",
      "      ndata_schemes={'feat': Scheme(shape=(1,), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
      "time: 103 ms (started: 2023-10-01 22:44:28 -05:00)\n"
     ]
    }
   ],
   "source": [
    "nodes_data = pd.read_csv(\"{}/output/{}/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(dir, exp, groups_id[0], subgroups_id[groups_id[0]][0])).iloc[:, 2:]\n",
    "edges_data = pd.read_csv(\"{}/output/{}/preprocessing/graphs_data/edges_data_{}_{}.csv\".format(dir, exp, groups_id[0], subgroups_id[groups_id[0]][0]))\n",
    "\n",
    "dataset = CustomDataset(\"g1\", nodes_data, edges_data)\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 61.3 ms (started: 2023-10-01 22:44:28 -05:00)\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"Variant Graph Auto Encoder\")\n",
    "parser.add_argument(\n",
    "    \"--learning_rate\", type=float, default=1e-3, help=\"Initial learning rate.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--epochs\", \"-e\", type=int, default=300, help=\"Number of epochs to train.\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hidden1\",\n",
    "    \"-h1\",\n",
    "    type=int,\n",
    "    default=32,\n",
    "    help=\"Number of units in hidden layer 1.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--hidden2\",\n",
    "    \"-h2\",\n",
    "    type=int,\n",
    "    default=dimension,\n",
    "    help=\"Number of units in hidden layer 2.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--datasrc\",\n",
    "    \"-s\",\n",
    "    type=str,\n",
    "    default=\"dgl\",\n",
    "    help=\"Dataset download from dgl Dataset or website.\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dataset\", \"-d\", type=str, default=\"cora\", help=\"Dataset string.\"\n",
    ")\n",
    "parser.add_argument(\"--gpu_id\", type=int, default=0, help=\"GPU id to use.\")\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "\n",
    "# check device\n",
    "device = torch.device(\n",
    "    \"cuda:{}\".format(args.gpu_id) if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "# device = \"cpu\"\n",
    "device\n",
    "# roc_means = []\n",
    "# ap_means = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 60.3 ms (started: 2023-10-01 22:44:28 -05:00)\n"
     ]
    }
   ],
   "source": [
    "def compute_loss_para(adj):\n",
    "    pos_weight = (adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "    norm = (\n",
    "        adj.shape[0]\n",
    "        * adj.shape[0]\n",
    "        / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "    )\n",
    "    weight_mask = adj.view(-1) == 1\n",
    "    weight_tensor = torch.ones(weight_mask.size(0)).to(device)\n",
    "    weight_tensor[weight_mask] = pos_weight\n",
    "    return weight_tensor, norm\n",
    "\n",
    "def get_acc(adj_rec, adj_label):\n",
    "    labels_all = adj_label.view(-1).long()\n",
    "    preds_all = (adj_rec > 0.5).view(-1).long()\n",
    "    accuracy = (preds_all == labels_all).sum().float() / labels_all.size(0)\n",
    "    return accuracy\n",
    "\n",
    "def get_scores(edges_pos, edges_neg, adj_rec):\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    adj_rec = adj_rec.cpu()\n",
    "    # Predict on test set of edges\n",
    "    preds = []\n",
    "    for e in edges_pos:\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]].item()))\n",
    "\n",
    "    preds_neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]].data))\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "\n",
    "    return roc_score, ap_score\n",
    "\n",
    "def train_vgae(graph, args, method, group, subgroup):\n",
    "    # extract node features\n",
    "    # print(device)\n",
    "    feats = graph.ndata.pop(\"feat\").to(device)\n",
    "    in_dim = feats.shape[-1]\n",
    "    # print(in_dim)\n",
    "\n",
    "    # generate input\n",
    "    adj_orig = graph.adj_external().to_dense()\n",
    "\n",
    "    # build test set with 10% positive links\n",
    "    (\n",
    "        train_edge_idx,\n",
    "        val_edges,\n",
    "        val_edges_false,\n",
    "        test_edges,\n",
    "        test_edges_false,\n",
    "    ) = mask_test_edges_dgl(graph, adj_orig)\n",
    "\n",
    "    graph = graph.to(device)\n",
    "\n",
    "    # create train graph\n",
    "    train_edge_idx = torch.tensor(train_edge_idx).to(device)\n",
    "    train_graph = dgl.edge_subgraph(graph, train_edge_idx, relabel_nodes=False)\n",
    "    train_graph = train_graph.to(device)\n",
    "    adj = train_graph.adj_external().to_dense().to(device)\n",
    "\n",
    "    # compute loss parameters\n",
    "    weight_tensor, norm = compute_loss_para(adj)\n",
    "\n",
    "    # create model\n",
    "    vgae_model = model.VGAEModel(in_dim, args.hidden1, args.hidden2)\n",
    "    vgae_model = vgae_model.to(device)\n",
    "\n",
    "    # create training component\n",
    "    optimizer = torch.optim.Adam(vgae_model.parameters(), lr=args.learning_rate)\n",
    "    \"\"\" print(\n",
    "        \"Total Parameters:\",\n",
    "        sum([p.nelement() for p in vgae_model.parameters()]),\n",
    "    ) \"\"\"\n",
    "\n",
    "    # create training epoch\n",
    "    for epoch in tqdm(range(args.epochs)):\n",
    "        t = time.time()\n",
    "\n",
    "        # Training and validation using a full graph\n",
    "        vgae_model.train()\n",
    "\n",
    "        logits = vgae_model.forward(graph, feats)\n",
    "\n",
    "        # compute loss\n",
    "        loss = norm * F.binary_cross_entropy(\n",
    "            logits.view(-1), adj.view(-1), weight=weight_tensor\n",
    "        )\n",
    "        kl_divergence = (\n",
    "            0.5\n",
    "            / logits.size(0)\n",
    "            * (\n",
    "                1\n",
    "                + 2 * vgae_model.log_std\n",
    "                - vgae_model.mean**2\n",
    "                - torch.exp(vgae_model.log_std) ** 2\n",
    "            )\n",
    "            .sum(1)\n",
    "            .mean()\n",
    "        )\n",
    "        loss -= kl_divergence\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # train_acc = get_acc(logits, adj)\n",
    "\n",
    "        # val_roc, val_ap = get_scores(val_edges, val_edges_false, logits)\n",
    "\n",
    "        # Print out performance\n",
    "        \"\"\" print(\n",
    "            \"Epoch:\",\n",
    "            \"%04d\" % (epoch + 1),\n",
    "            \"train_loss=\",\n",
    "            \"{:.5f}\".format(loss.item()),\n",
    "            \"train_acc=\",\n",
    "            \"{:.5f}\".format(train_acc),\n",
    "            \"val_roc=\",\n",
    "            \"{:.5f}\".format(val_roc),\n",
    "            \"val_ap=\",\n",
    "            \"{:.5f}\".format(val_ap),\n",
    "            \"time=\",\n",
    "            \"{:.5f}\".format(time.time() - t),\n",
    "        ) \"\"\"\n",
    "\n",
    "    \"\"\" test_roc, test_ap = get_scores(test_edges, test_edges_false, logits)\n",
    "    # roc_means.append(test_roc)\n",
    "    # ap_means.append(test_ap)\n",
    "    print(\n",
    "        \"End of training!\",\n",
    "        \"test_roc=\",\n",
    "        \"{:.5f}\".format(test_roc),\n",
    "        \"test_ap=\",\n",
    "        \"{:.5f}\".format(test_ap),\n",
    "    ) \"\"\"\n",
    "\n",
    "    embeds = vgae_model.encoder(graph, feats)\n",
    "    embeds = embeds.cpu().detach()\n",
    "\n",
    "    df_node_embeddings = pd.DataFrame(data=embeds)\n",
    "    df_node_embeddings\n",
    "\n",
    "    # save\n",
    "    df_node_embeddings.to_csv(\"{}/output/{}/node_embeddings/node-embeddings_{}_{}_{}.csv\".format(dir, exp, method, group, subgroup), index=True)\n",
    "    # print(\"Save node embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 99.8 ms (started: 2023-10-01 22:44:29 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups id:\t {'pck1': ['1', '2', '3'], 'zwf1': ['1', '2'], 'WT': ['1', '2', '3', '4', '5']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 300/300 [00:03<00:00, 99.16it/s] \n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 300/300 [00:02<00:00, 104.57it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 300/300 [00:02<00:00, 104.69it/s]\n",
      "100%|██████████| 3/3 [00:09<00:00,  3.02s/it]\n",
      " 33%|███▎      | 1/3 [00:09<00:18,  9.08s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 300/300 [00:02<00:00, 104.15it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 300/300 [00:02<00:00, 104.19it/s]\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.91s/it]\n",
      " 67%|██████▋   | 2/3 [00:14<00:07,  7.16s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 300/300 [00:02<00:00, 103.39it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 300/300 [00:02<00:00, 102.62it/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "100%|██████████| 300/300 [00:02<00:00, 103.77it/s]\n",
      "\n",
      "\u001b[A/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [96,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [97,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [98,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [99,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [100,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "  1%|          | 2/300 [00:00<00:04, 66.30it/s]/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [101,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [102,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [103,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [104,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [105,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [106,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [107,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [108,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [109,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [110,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [111,0,0] Assert\n",
      " 60%|██████    | 3/5 [00:08<00:05,  2.95s/it]ion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [112,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [113,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [114,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [115,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [116,0,0] Assertion `input_val >= zero && input_val <= one` f\n",
      " 67%|██████▋   | 2/3 [00:23<00:11, 11.88s/it]ailed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [117,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [118,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [119,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [120,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [121,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [122,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [123,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [124,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [125,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [126,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [18,0,0], thread: [127,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [64,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [65,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [66,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [67,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [68,0,0] \n",
      "Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [69,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [70,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [71,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [72,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [73,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [74,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [75,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [76,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [77,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [78,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [79,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [80,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [81,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [82,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [83,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [84,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [85,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [86,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [87,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [88,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [89,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [90,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [91,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [92,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [93,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [94,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [11,0,0], thread: [95,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [32,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [33,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [34,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [35,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [36,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [37,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [38,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [39,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [40,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [41,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [42,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [43,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [44,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [45,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [46,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [47,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [48,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [49,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [50,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [51,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [52,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [53,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [54,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [55,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [56,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [57,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [58,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [59,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [60,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [61,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [62,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n",
      "/opt/conda/conda-bld/pytorch_1678402411778/work/aten/src/ATen/native/cuda/Loss.cu:92: operator(): block: [28,0,0], thread: [63,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/catolica/Project/Python/GNN_Unsupervised/vgae/3_vgae_go.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bicoba/home/catolica/Project/Python/GNN_Unsupervised/vgae/3_vgae_go.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m graph \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bicoba/home/catolica/Project/Python/GNN_Unsupervised/vgae/3_vgae_go.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# train\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bicoba/home/catolica/Project/Python/GNN_Unsupervised/vgae/3_vgae_go.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m train_vgae(graph, args, method, group, subgroup)\n",
      "\u001b[1;32m/home/catolica/Project/Python/GNN_Unsupervised/vgae/3_vgae_go.ipynb Cell 14\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bicoba/home/catolica/Project/Python/GNN_Unsupervised/vgae/3_vgae_go.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=84'>85</a>\u001b[0m \u001b[39m# Training and validation using a full graph\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bicoba/home/catolica/Project/Python/GNN_Unsupervised/vgae/3_vgae_go.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m vgae_model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bicoba/home/catolica/Project/Python/GNN_Unsupervised/vgae/3_vgae_go.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m logits \u001b[39m=\u001b[39m vgae_model\u001b[39m.\u001b[39;49mforward(graph, feats)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bicoba/home/catolica/Project/Python/GNN_Unsupervised/vgae/3_vgae_go.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39m# compute loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bicoba/home/catolica/Project/Python/GNN_Unsupervised/vgae/3_vgae_go.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m loss \u001b[39m=\u001b[39m norm \u001b[39m*\u001b[39m F\u001b[39m.\u001b[39mbinary_cross_entropy(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bicoba/home/catolica/Project/Python/GNN_Unsupervised/vgae/3_vgae_go.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m     logits\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), adj\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), weight\u001b[39m=\u001b[39mweight_tensor\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bicoba/home/catolica/Project/Python/GNN_Unsupervised/vgae/3_vgae_go.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Project/Python/GNN_Unsupervised/vgae/model.py:60\u001b[0m, in \u001b[0;36mVGAEModel.forward\u001b[0;34m(self, g, features)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, g, features):\n\u001b[0;32m---> 60\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(g, features)\n\u001b[1;32m     61\u001b[0m     adj_rec \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(z)\n\u001b[1;32m     62\u001b[0m     \u001b[39mreturn\u001b[39;00m adj_rec\n",
      "File \u001b[0;32m~/Project/Python/GNN_Unsupervised/vgae/model.py:43\u001b[0m, in \u001b[0;36mVGAEModel.encoder\u001b[0;34m(self, g, features)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencoder\u001b[39m(\u001b[39mself\u001b[39m, g, features):\n\u001b[0;32m---> 43\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayers[\u001b[39m0\u001b[39;49m](g, features)\n\u001b[1;32m     44\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m1\u001b[39m](g, h)\n\u001b[1;32m     45\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog_std \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[\u001b[39m2\u001b[39m](g, h)\n",
      "File \u001b[0;32m~/miniconda3/envs/meta_net_3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/meta_net_3.10/lib/python3.10/site-packages/dgl/nn/pytorch/conv/graphconv.py:428\u001b[0m, in \u001b[0;36mGraphConv.forward\u001b[0;34m(self, graph, feat, weight, edge_weight)\u001b[0m\n\u001b[1;32m    426\u001b[0m feat_src, feat_dst \u001b[39m=\u001b[39m expand_as_pair(feat, graph)\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_norm \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mleft\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 428\u001b[0m     degs \u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39;49mout_degrees()\u001b[39m.\u001b[39mto(feat_src)\u001b[39m.\u001b[39mclamp(\u001b[39mmin\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    429\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_norm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mboth\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    430\u001b[0m         norm \u001b[39m=\u001b[39m th\u001b[39m.\u001b[39mpow(degs, \u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/meta_net_3.10/lib/python3.10/site-packages/dgl/heterograph.py:3748\u001b[0m, in \u001b[0;36mDGLGraph.out_degrees\u001b[0;34m(self, u, etype)\u001b[0m\n\u001b[1;32m   3745\u001b[0m     u \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrcnodes(srctype)\n\u001b[1;32m   3746\u001b[0m u_tensor \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mprepare_tensor(\u001b[39mself\u001b[39m, u, \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3747\u001b[0m \u001b[39mif\u001b[39;00m F\u001b[39m.\u001b[39mas_scalar(\n\u001b[0;32m-> 3748\u001b[0m     F\u001b[39m.\u001b[39msum(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhas_nodes(u_tensor, ntype\u001b[39m=\u001b[39;49msrctype), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m   3749\u001b[0m ) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(u_tensor):\n\u001b[1;32m   3750\u001b[0m     \u001b[39mraise\u001b[39;00m DGLError(\u001b[39m\"\u001b[39m\u001b[39mu contains invalid node IDs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   3751\u001b[0m deg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39mout_degrees(etid, utils\u001b[39m.\u001b[39mprepare_tensor(\u001b[39mself\u001b[39m, u, \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/meta_net_3.10/lib/python3.10/site-packages/dgl/heterograph.py:2924\u001b[0m, in \u001b[0;36mDGLGraph.has_nodes\u001b[0;34m(self, vid, ntype)\u001b[0m\n\u001b[1;32m   2877\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return whether the graph contains the given nodes.\u001b[39;00m\n\u001b[1;32m   2878\u001b[0m \n\u001b[1;32m   2879\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2921\u001b[0m \u001b[39mtensor([False,  True,  True])\u001b[39;00m\n\u001b[1;32m   2922\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2923\u001b[0m vid_tensor \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mprepare_tensor(\u001b[39mself\u001b[39m, vid, \u001b[39m\"\u001b[39m\u001b[39mvid\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2924\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(vid_tensor) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m F\u001b[39m.\u001b[39;49mas_scalar(F\u001b[39m.\u001b[39;49mmin(vid_tensor, \u001b[39m0\u001b[39;49m)) \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\n\u001b[1;32m   2925\u001b[0m     vid_tensor\n\u001b[1;32m   2926\u001b[0m ):\n\u001b[1;32m   2927\u001b[0m     \u001b[39mraise\u001b[39;00m DGLError(\u001b[39m\"\u001b[39m\u001b[39mAll IDs must be non-negative integers.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2928\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39mhas_nodes(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_ntype_id(ntype), vid_tensor)\n",
      "File \u001b[0;32m~/miniconda3/envs/meta_net_3.10/lib/python3.10/site-packages/dgl/backend/pytorch/tensor.py:56\u001b[0m, in \u001b[0;36mas_scalar\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mas_scalar\u001b[39m(data):\n\u001b[0;32m---> 56\u001b[0m     \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39;49mitem()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 24.6 s (started: 2023-10-01 22:44:29 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# get node embeddings\n",
    "seed = 46\n",
    "for option in options:\n",
    "    if option:\n",
    "        for group in groups_id:\n",
    "            subgroups_id[group] = [option]\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    else:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        pass\n",
    "        \n",
    "    print(\"Subgroups id:\\t\", subgroups_id)\n",
    "    \n",
    "    for group in tqdm(groups_id):\n",
    "        for subgroup in tqdm(subgroups_id[group]):\n",
    "            nodes_data = pd.read_csv(\"{}/output/{}/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(dir, exp, group, subgroup)).iloc[:, 2:]\n",
    "            edges_data = pd.read_csv(\"{}/output/{}/preprocessing/graphs_data/edges_data_{}_{}.csv\".format(dir, exp, group, subgroup))\n",
    "\n",
    "            # read dataset\n",
    "            # data = load_data(args)\n",
    "            data = CustomDataset(\"g_{}_{}\".format(group, subgroup), nodes_data, edges_data)\n",
    "            graph = data[0]\n",
    "\n",
    "            # train\n",
    "            train_vgae(graph, args, method, group, subgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.256895</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>-0.225627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.396508</td>\n",
       "      <td>-0.662661</td>\n",
       "      <td>1.337376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.353824</td>\n",
       "      <td>0.572614</td>\n",
       "      <td>-1.135151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.385863</td>\n",
       "      <td>-1.242808</td>\n",
       "      <td>-1.354239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.235456</td>\n",
       "      <td>1.068773</td>\n",
       "      <td>1.373220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2\n",
       "0 -0.256895  0.001080 -0.225627\n",
       "1  0.396508 -0.662661  1.337376\n",
       "2  0.353824  0.572614 -1.135151\n",
       "3 -1.385863 -1.242808 -1.354239\n",
       "4 -0.235456  1.068773  1.373220"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.9 ms (started: 2023-09-30 18:24:37 -05:00)\n"
     ]
    }
   ],
   "source": [
    "df_node_embeddings = pd.read_csv(\"{}/output/{}/node_embeddings/node-embeddings_{}_{}_{}.csv\".format(dir, exp, method, groups_id[0],                                                                                            subgroups_id[groups_id[0]][0]), index_col=0)\n",
    "df_node_embeddings.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
