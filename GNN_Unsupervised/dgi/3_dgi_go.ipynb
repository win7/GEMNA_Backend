{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 910 µs (started: 2023-10-20 13:41:57 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import argparse, time\n",
    "\n",
    "import dgl\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgi import Classifier, DGI\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import load_data, register_data_args, DGLDataset\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 12.2 ms (started: 2023-10-20 13:41:57 -05:00)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 782 µs (started: 2023-10-20 13:41:57 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from utils.utils_go import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 386 µs (started: 2023-10-20 13:41:57 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# torch.manual_seed(42)\n",
    "# np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.24 ms (started: 2023-10-20 13:41:57 -05:00)\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ealvarez/Project/GNN_Unsupervised\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ealvarez/Project/GNN_Unsupervised/parameters.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/ealvarez/Project/GNN_Unsupervised/dgi/3_dgi_go.ipynb Cell 8\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.19.4.251/home/ealvarez/Project/GNN_Unsupervised/dgi/3_dgi_go.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mdir\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.19.4.251/home/ealvarez/Project/GNN_Unsupervised/dgi/3_dgi_go.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# opening JSON file\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.19.4.251/home/ealvarez/Project/GNN_Unsupervised/dgi/3_dgi_go.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m/parameters.json\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\u001b[39mdir\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.19.4.251/home/ealvarez/Project/GNN_Unsupervised/dgi/3_dgi_go.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m params \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(file)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B172.19.4.251/home/ealvarez/Project/GNN_Unsupervised/dgi/3_dgi_go.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m exp \u001b[39m=\u001b[39m params[\u001b[39m\"\u001b[39m\u001b[39mexp\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/meta_net_3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ealvarez/Project/GNN_Unsupervised/parameters.json'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 151 ms (started: 2023-10-20 13:41:57 -05:00)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "dir = os.path.dirname(os.getcwd())\n",
    "print(dir)\n",
    "\n",
    "# opening JSON file\n",
    "file = open(\"{}/parameters.json\".format(dir))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "method = \"dgi\"\n",
    "print(\"Method:\\t\\t\", method)\n",
    "\n",
    "dimension = params[\"dimension\"]\n",
    "print(\"Dimension:\\t\", dimension)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "option = params[\"option\"]\n",
    "print(\"Option:\\t\\t\", option)\n",
    "\n",
    "options = params[\"options\"]\n",
    "print(\"Options:\\t\", options)\n",
    "\n",
    "\"\"\" if option:\n",
    "    for group in groups_id:\n",
    "        subgroups_id[group] = [option]\n",
    "    print(\"Subgroups id:\\t\", subgroups_id) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 55.2 ms (started: 2023-10-01 23:04:46 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# custom dataset\n",
    "\n",
    "class CustomDataset(DGLDataset):\n",
    "    def __init__(self, name, nodes_data, edges_data):\n",
    "        self.dir = dir\n",
    "        self.nodes_data = nodes_data\n",
    "        self.edges_data = edges_data\n",
    "        super().__init__(name=name)\n",
    "       \n",
    "    def process(self):\n",
    "        node_features = torch.from_numpy(self.nodes_data.to_numpy())\n",
    "        # node_features = torch.from_numpy(np.log10(self.nodes_data[\"degree\"].to_numpy()))\n",
    "        node_features = node_features.to(torch.float32)\n",
    "        # node_features = torch.reshape(node_features, (-1, 1))\n",
    "\n",
    "        # node_labels = torch.from_numpy(self.nodes_data[\"id\"].to_numpy())\n",
    "        # node_labels = node_labels.to(torch.float32)\n",
    "\n",
    "        edge_features = torch.from_numpy(self.edges_data[\"weight\"].to_numpy())\n",
    "        edges_src = torch.from_numpy(self.edges_data[\"source\"].to_numpy())\n",
    "        edges_dst = torch.from_numpy(self.edges_data[\"target\"].to_numpy())\n",
    "\n",
    "        self.graph = dgl.graph(\n",
    "            (edges_src, edges_dst), num_nodes=self.nodes_data.shape[0]\n",
    "        )\n",
    "        self.graph.ndata[\"feat\"] = node_features\n",
    "        # self.graph.ndata[\"label\"] = node_labels\n",
    "        self.graph.edata[\"weight\"] = edge_features\n",
    "\n",
    "        # If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "        n_nodes = self.nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train : n_train + n_val] = True\n",
    "        test_mask[n_train + n_val :] = True\n",
    "        self.graph.ndata[\"train_mask\"] = train_mask\n",
    "        self.graph.ndata[\"val_mask\"] = val_mask\n",
    "        self.graph.ndata[\"test_mask\"] = test_mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "def train_dgi(graph, args, method, group, subgroup):\n",
    "    features = torch.FloatTensor(graph.ndata[\"feat\"])\n",
    "    # print(features.shape)\n",
    "    # labels = torch.LongTensor(graph.ndata[\"label\"])\n",
    "    if hasattr(torch, \"BoolTensor\"):\n",
    "        train_mask = torch.BoolTensor(graph.ndata[\"train_mask\"])\n",
    "        val_mask = torch.BoolTensor(graph.ndata[\"val_mask\"])\n",
    "        test_mask = torch.BoolTensor(graph.ndata[\"test_mask\"])\n",
    "    else:\n",
    "        train_mask = torch.ByteTensor(graph.ndata[\"train_mask\"])\n",
    "        val_mask = torch.ByteTensor(graph.ndata[\"val_mask\"])\n",
    "        test_mask = torch.ByteTensor(graph.ndata[\"test_mask\"])\n",
    "    in_feats = features.shape[1]\n",
    "    # n_classes = data.num_classes\n",
    "    n_edges = graph.num_edges()\n",
    "\n",
    "    if args.gpu < 0:\n",
    "        cuda = False\n",
    "    else:\n",
    "        cuda = True\n",
    "        torch.cuda.set_device(args.gpu)\n",
    "        features = features.cuda()\n",
    "        # labels = labels.cuda()\n",
    "        train_mask = train_mask.cuda()\n",
    "        val_mask = val_mask.cuda()\n",
    "        test_mask = test_mask.cuda()\n",
    "\n",
    "    # add self loop\n",
    "    if args.self_loop:\n",
    "        # print(\"self_loop\")\n",
    "        graph = dgl.remove_self_loop(graph)\n",
    "        graph = dgl.add_self_loop(graph)\n",
    "    n_edges = graph.num_edges()\n",
    "\n",
    "    if args.gpu >= 0:\n",
    "        graph = graph.to(args.gpu)\n",
    "    # create DGI model\n",
    "    dgi = DGI(\n",
    "        graph,\n",
    "        in_feats,\n",
    "        args.n_hidden,\n",
    "        args.n_layers,\n",
    "        nn.PReLU(args.n_hidden),\n",
    "        args.dropout,\n",
    "    )\n",
    "\n",
    "    if cuda:\n",
    "        dgi.cuda()\n",
    "\n",
    "    dgi_optimizer = torch.optim.Adam(\n",
    "        dgi.parameters(), lr=args.dgi_lr, weight_decay=args.weight_decay\n",
    "    )\n",
    "\n",
    "    # train deep graph infomax\n",
    "    cnt_wait = 0\n",
    "    best = 1e9\n",
    "    best_t = 0\n",
    "    dur = []\n",
    "    for epoch in range(args.n_dgi_epochs):\n",
    "        dgi.train()\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "\n",
    "        dgi_optimizer.zero_grad()\n",
    "        loss = dgi(features)\n",
    "        loss.backward()\n",
    "        dgi_optimizer.step()\n",
    "\n",
    "        if loss < best:\n",
    "            best = loss\n",
    "            best_t = epoch\n",
    "            cnt_wait = 0\n",
    "            torch.save(dgi.state_dict(), \"best_dgi.pkl\")\n",
    "        else:\n",
    "            cnt_wait += 1\n",
    "\n",
    "        if cnt_wait == args.patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        \"\"\" print(\n",
    "            \"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
    "            \"ETputs(KTEPS) {:.2f}\".format(\n",
    "                epoch, np.mean(dur), loss.item(), n_edges / np.mean(dur) / 1000\n",
    "            )\n",
    "        ) \"\"\"\n",
    "\n",
    "    embeds = dgi.encoder(features, corrupt=False)\n",
    "    embeds = embeds.cpu().detach()\n",
    "\n",
    "    df_node_embeddings = pd.DataFrame(data=embeds)\n",
    "    df_node_embeddings\n",
    "\n",
    "    # save\n",
    "    df_node_embeddings.to_csv(\"{}/output/{}/node_embeddings/node-embeddings_{}_{}_{}.csv\".format(dir, exp, method, group, subgroup), index=True)\n",
    "    # print(\"Save node embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ealvarez/Project/GNN_Unsupervised/dgi/3_dgi_go.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B172.19.4.251/home/ealvarez/Project/GNN_Unsupervised/dgi/3_dgi_go.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m nodes_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/output/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/preprocessing/graphs_data/nodes_data_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mdir\u001b[39m, exp, groups_id[\u001b[39m0\u001b[39m], subgroups_id[groups_id[\u001b[39m0\u001b[39m]][\u001b[39m0\u001b[39m]))\u001b[39m.\u001b[39miloc[:, \u001b[39m2\u001b[39m:]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.19.4.251/home/ealvarez/Project/GNN_Unsupervised/dgi/3_dgi_go.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m edges_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/output/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/preprocessing/graphs_data/edges_data_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mdir\u001b[39m, exp, groups_id[\u001b[39m0\u001b[39m], subgroups_id[groups_id[\u001b[39m0\u001b[39m]][\u001b[39m0\u001b[39m]))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B172.19.4.251/home/ealvarez/Project/GNN_Unsupervised/dgi/3_dgi_go.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m dataset \u001b[39m=\u001b[39m CustomDataset(\u001b[39m\"\u001b[39m\u001b[39mg1\u001b[39m\u001b[39m\"\u001b[39m, nodes_data, edges_data)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exp' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.2 ms (started: 2023-10-20 13:41:59 -05:00)\n"
     ]
    }
   ],
   "source": [
    "nodes_data = pd.read_csv(\"{}/output/{}/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(dir, exp, groups_id[0], subgroups_id[groups_id[0]][0])).iloc[:, 2:]\n",
    "edges_data = pd.read_csv(\"{}/output/{}/preprocessing/graphs_data/edges_data_{}_{}.csv\".format(dir, exp, groups_id[0], subgroups_id[groups_id[0]][0]))\n",
    "\n",
    "dataset = CustomDataset(\"g1\", nodes_data, edges_data)\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dataset='cora', dropout=0.0, gpu=0, dgi_lr=0.001, classifier_lr=0.01, n_dgi_epochs=300, n_classifier_epochs=300, n_hidden=3, n_layers=3, weight_decay=0.0, patience=20, self_loop=True)\n",
      "time: 73.2 ms (started: 2023-10-01 23:04:46 -05:00)\n"
     ]
    }
   ],
   "source": [
    "# params\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"DGI\")\n",
    "# register_data_args(parser)\n",
    "parser.add_argument(\n",
    "    \"--dataset\",\n",
    "    type=str,\n",
    "    default=\"cora\",\n",
    "    required=False,\n",
    "    help=\"The input dataset. Can be cora, citeseer, pubmed, syn(synthetic dataset) or reddit\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--dropout\", type=float, default=0.0, help=\"dropout probability\"\n",
    ")\n",
    "parser.add_argument(\"--gpu\", type=int, default=0, help=\"gpu\")\n",
    "parser.add_argument(\n",
    "    \"--dgi-lr\", type=float, default=1e-3, help=\"dgi learning rate\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--classifier-lr\",\n",
    "    type=float,\n",
    "    default=1e-2,\n",
    "    help=\"classifier learning rate\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-dgi-epochs\",\n",
    "    type=int,\n",
    "    default=300,\n",
    "    help=\"number of training epochs\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-classifier-epochs\",\n",
    "    type=int,\n",
    "    default=300,\n",
    "    help=\"number of training epochs\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-hidden\", type=int, default=512, help=\"number of hidden gcn units\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--n-layers\", type=int, default=3, help=\"number of hidden gcn layers\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--weight-decay\", type=float, default=0.0, help=\"Weight for L2 loss\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--patience\", type=int, default=20, help=\"early stop patience condition\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--self-loop\",\n",
    "    action=\"store_true\",\n",
    "    help=\"graph self-loop (default=False)\",\n",
    ")\n",
    "parser.set_defaults(self_loop=True)\n",
    "parser.set_defaults(n_hidden=dimension)\n",
    "parser.set_defaults(n_layers=3)\n",
    "args = parser.parse_args(\"\")\n",
    "\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgroups id:\t {'pck1': ['1', '2', '3'], 'zwf1': ['1', '2'], 'WT': ['1', '2', '3', '4', '5']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:11<00:00,  3.78s/it]\n",
      " 33%|███▎      | 1/3 [00:11<00:22, 11.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:08<00:00,  4.07s/it]\n",
      " 67%|██████▋   | 2/3 [00:19<00:09,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.94s/it]\n",
      "100%|██████████| 3/3 [00:29<00:00,  9.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n",
      "Subgroups id:\t {'pck1': ['str'], 'zwf1': ['str'], 'WT': ['str']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      " 33%|███▎      | 1/3 [00:01<00:03,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:04<00:00,  4.15s/it]\n",
      " 67%|██████▋   | 2/3 [00:06<00:03,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.91s/it]\n",
      "100%|██████████| 3/3 [00:10<00:00,  3.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n",
      "Subgroups id:\t {'pck1': ['dyn'], 'zwf1': ['dyn'], 'WT': ['dyn']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.29s/it]\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.54s/it]\n",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.38s/it]\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping!\n",
      "time: 45.6 s (started: 2023-10-01 23:04:46 -05:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get node embeddings\n",
    "seed = 46\n",
    "for option in options:\n",
    "    if option:\n",
    "        for group in groups_id:\n",
    "            subgroups_id[group] = [option]\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    else:\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        pass\n",
    "    print(\"Subgroups id:\\t\", subgroups_id)\n",
    "    \n",
    "    for group in tqdm(groups_id):\n",
    "        for subgroup in tqdm(subgroups_id[group]):\n",
    "            nodes_data = pd.read_csv(\"{}/output/{}/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(dir, exp, group, subgroup)).iloc[:, 2:]\n",
    "            edges_data = pd.read_csv(\"{}/output/{}/preprocessing/graphs_data/edges_data_{}_{}.csv\".format(dir, exp, group, subgroup))\n",
    "\n",
    "            # read dataset\n",
    "            # data = load_data(args)\n",
    "            data = CustomDataset(\"g_{}_{}\".format(group, subgroup), nodes_data, edges_data)\n",
    "            graph = data[0]\n",
    "\n",
    "            # train\n",
    "            train_dgi(graph, args, method, group, subgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028216</td>\n",
       "      <td>0.038473</td>\n",
       "      <td>-0.030870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027113</td>\n",
       "      <td>0.040283</td>\n",
       "      <td>-0.031338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.026278</td>\n",
       "      <td>0.041659</td>\n",
       "      <td>-0.031701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.025606</td>\n",
       "      <td>0.042774</td>\n",
       "      <td>-0.032009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.025040</td>\n",
       "      <td>0.043718</td>\n",
       "      <td>-0.032287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.273044</td>\n",
       "      <td>-0.811768</td>\n",
       "      <td>-0.166852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>0.293061</td>\n",
       "      <td>-0.884483</td>\n",
       "      <td>-0.178111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.311482</td>\n",
       "      <td>-0.950744</td>\n",
       "      <td>-0.188288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.349556</td>\n",
       "      <td>-1.089457</td>\n",
       "      <td>-0.209681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.404017</td>\n",
       "      <td>-1.288011</td>\n",
       "      <td>-0.240219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2\n",
       "0    0.028216  0.038473 -0.030870\n",
       "1    0.027113  0.040283 -0.031338\n",
       "2    0.026278  0.041659 -0.031701\n",
       "3    0.025606  0.042774 -0.032009\n",
       "4    0.025040  0.043718 -0.032287\n",
       "..        ...       ...       ...\n",
       "355  0.273044 -0.811768 -0.166852\n",
       "356  0.293061 -0.884483 -0.178111\n",
       "357  0.311482 -0.950744 -0.188288\n",
       "358  0.349556 -1.089457 -0.209681\n",
       "359  0.404017 -1.288011 -0.240219\n",
       "\n",
       "[360 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.3 ms (started: 2023-10-01 23:05:32 -05:00)\n"
     ]
    }
   ],
   "source": [
    "df_node_embeddings = pd.read_csv(\"{}/output/{}/node_embeddings/node-embeddings_{}_{}_{}.csv\".format(dir, exp, method, groups_id[0], \n",
    "                                                                                                    subgroups_id[groups_id[0]][0]), index_col=0)\n",
    "df_node_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
