{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from IPython.display import display\n",
    "import algorithmx\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# from utils.utils_go import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# %run a_format_go.py\n",
    "# %run b_prepro_go.py\n",
    "# %run c-d_node-edge_go.py\n",
    "# %run e_change_go.py\n",
    "# %run f_biocyc_go.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# %run experiments.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# print(exp)\n",
    "exp = \"387f0495-9927-4296-833c-e64fa7c4ac62\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "controls = params[\"controls\"]\n",
    "print(\"Control:\\t\", controls)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Subgroup</th>\n",
       "      <th>Num. nodes</th>\n",
       "      <th>Num. edges</th>\n",
       "      <th>Density</th>\n",
       "      <th>Diameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>dyn</td>\n",
       "      <td>3551</td>\n",
       "      <td>2956123</td>\n",
       "      <td>0.469001</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red</td>\n",
       "      <td>dyn</td>\n",
       "      <td>3549</td>\n",
       "      <td>2959604</td>\n",
       "      <td>0.470082</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Orange</td>\n",
       "      <td>dyn</td>\n",
       "      <td>3550</td>\n",
       "      <td>2964634</td>\n",
       "      <td>0.470616</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Group Subgroup  Num. nodes  Num. edges   Density  Diameter\n",
       "0  Yellow      dyn        3551     2956123  0.469001         3\n",
       "1     Red      dyn        3549     2959604  0.470082         3\n",
       "2  Orange      dyn        3550     2964634  0.470616         3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preprocessing = pd.read_csv(\"experiments/output/{}/preprocessing/graphs_data/summary.csv\".format(exp))\n",
    "df_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "print(df_preprocessing.to_latex(index=False, formatters={\"name\": str.upper}, float_format=\"{:.2f}\".format)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "path = \"experiments/output/{}/correlations\".format(exp)\n",
    "dir_list = sorted(os.listdir(path))\n",
    "\n",
    "for dir in dir_list:\n",
    "\tprint(dir)\n",
    "\tdf_matrix = pd.read_csv(\"experiments/output/{}/correlations/{}\".format(exp, dir), index_col=0)\n",
    "\t\n",
    "\tplt.imshow(df_matrix, cmap=\"coolwarm\", interpolation=\"none\")\n",
    "\tplt.colorbar()\n",
    "\tplt.title(dir.split(\".\")[0][13:])\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node-Edge embeddings (common subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "f = \"f1\" # change: f1, f2\n",
    "\n",
    "df_process = pd.read_csv(\"experiments/output/{}/common_edges/summary_{}.csv\".format(exp, f))\n",
    "df_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\"\"\"vdf_comparation_temp = df_process.set_index([\"Method\", \"Group\", \"Data var.\"])\n",
    "df_comparation_temp.sort_values(by=[\"Method\", \"Group\", \"Num. edges\"], ascending=False, inplace=True)\n",
    "ax = df_comparation_temp.plot.bar(rot=90)\n",
    "ax.grid() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_join_raw = pd.read_csv(\"experiments/input/{}_raw.csv\".format(exp), index_col=0, usecols=[0, 1, 2, 3])        \n",
    "# df_join_raw.columns = [\"mz\", \"name\"]\n",
    "df_join_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# details\n",
    "list_details = []\n",
    "\n",
    "for group in groups_id:\n",
    "\tdf_common_edges = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}.csv\".format(exp, \"greedy\", group, \"none\"))\n",
    "\tG = nx.from_pandas_edgelist(df_common_edges, edge_attr=[\"weight\"])\n",
    "\tnodes = list(G.nodes())\n",
    "\tdf_nodes_raw = df_join_raw.loc[nodes]\n",
    "\t\n",
    "\tnum_nodes_name = len(df_nodes_raw[df_nodes_raw[\"Metabolite name\"] != \"Unknown\"])\n",
    "\t\n",
    "\tlist_details.append([\"greedy\", group, \"none\", G.number_of_nodes(), G.number_of_edges(), nx.density(G), num_nodes_name])\n",
    "\n",
    "for method in methods:\n",
    "\tfor group in groups_id:\n",
    "\t\tfor data_variation in data_variations:\n",
    "\t\t\tdf_edges_filter_weight_filter = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}_{}.csv\".format(exp, f, method, group, data_variation))\n",
    "\n",
    "\t\t\tG = nx.from_pandas_edgelist(df_edges_filter_weight_filter, \"source\", \"target\", edge_attr=\"weight\")\n",
    "\t\t\tnodes = list(G.nodes())\n",
    "\t\t\tdf_nodes_raw = df_join_raw.loc[nodes]\n",
    "\t\t\t\n",
    "\t\t\tnum_nodes_name = len(df_nodes_raw[df_nodes_raw[\"Metabolite name\"] != \"Unknown\"])\n",
    "\t\t\t\n",
    "\t\t\tlist_details.append([method, group, data_variation, G.number_of_nodes(), G.number_of_edges(), nx.density(G), num_nodes_name])\n",
    "\n",
    "df_details = pd.DataFrame(list_details, columns=[\"Method\", \"Group\", \"Data var.\", \"Num. nodes\", \"Num. edges\", \"Density\", \"With name\"])\n",
    "df_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# percentage\n",
    "\n",
    "max_nodes = df_details.iloc[:3, :][\"Num. nodes\"].to_list()\n",
    "max_nodes\n",
    "\n",
    "max_edges = df_details.iloc[:3, :][\"Num. edges\"].to_list()\n",
    "max_edges\n",
    "\n",
    "total = []\n",
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "for i in tqdm(df_details.index[:len(groups_id)]):\n",
    "\ttotal.append([df_details[\"Num. nodes\"][i], df_details[\"Num. edges\"][i]])\n",
    "\tnodes.append(\"{} ({}%)\".format(df_details[\"Num. nodes\"][i], round(df_details[\"Num. nodes\"][i]*100/df_details[\"Num. nodes\"][i], 2)))\n",
    "\tedges.append(\"{} ({}%)\".format(df_details[\"Num. edges\"][i], round(df_details[\"Num. edges\"][i]*100/df_details[\"Num. edges\"][i], 2)))\n",
    "\n",
    "index = 0\n",
    "c = 0\n",
    "for i in tqdm(df_details.index[len(groups_id):]):\n",
    "\tnodes.append(\"{} ({}%)\".format(df_details[\"Num. nodes\"][i], round(df_details[\"Num. nodes\"][i]*100/total[index][0], 2)))\n",
    "\tedges.append(\"{} ({}%)\".format(df_details[\"Num. edges\"][i], round(df_details[\"Num. edges\"][i]*100/total[index][1], 2)))\n",
    "\n",
    "\tc += 1\n",
    "\tif c % len(data_variations) == 0:\n",
    "\t\tindex = (index + 1) % len(groups_id)\n",
    "\t\t\n",
    "df_results_ = df_details.copy()\n",
    "df_results_[\"Num. nodes\"] = nodes\n",
    "df_results_[\"Num. edges\"] = edges\n",
    "df_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_results_.to_csv(\"z_percentage_mutan_random.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity analysis (change detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_changes = pd.read_csv(\"experiments/output/{}/changes/summary.csv\".format(exp))\n",
    "df_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_join_raw = pd.read_csv(\"experiments/input/{}_raw.csv\".format(exp), index_col=0, usecols=[0, 1, 2])        \n",
    "# df_join_raw.columns = [\"mz\", \"name\"]\n",
    "df_join_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# count metabolities by name in raw data\n",
    "size1 = len(df_join_raw)\n",
    "size2 = len(df_join_raw[df_join_raw[\"Metabolite name\"] != \"Unknown\"])\n",
    "print(size1, size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "methods.insert(0, \"greedy\")\n",
    "methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# details\n",
    "\n",
    "is_significant = False # change, True: significant changes (*), False: no significant changes (non-* and same labels)\n",
    "list_details = []\n",
    "\n",
    "for method in methods:\n",
    "\tif method == \"greedy\":\n",
    "\t\tdata_variations = [\"none\"]\n",
    "\telse:\n",
    "\t\tdata_variations = [\"none\", \"str\", \"dyn\"]\n",
    "\tfor data_variation in data_variations:\n",
    "\t\tfor group in groups:\n",
    "\t\t\tdf_change_filter = pd.read_csv(\"experiments/output/{}/changes/changes_edges_log2_{}_{}_{}_{}.csv\".format(exp, method, group[0], group[1], data_variation))\n",
    "\t\t\t\n",
    "\t\t\tif is_significant:\n",
    "\t\t\t\tdf_change_filter = df_change_filter[df_change_filter[\"significant\"] == \"*\"]\n",
    "\t\t\telse:\n",
    "\t\t\t\tdf_change_filter = df_change_filter[df_change_filter[\"significant\"] != \"*\"]\n",
    "\t\t\t\tdf_change_filter = df_change_filter[df_change_filter[\"label\"].isin([\"nn\", \"NN\", \"pp\", \"PP\"])]\n",
    "\t\t\t\n",
    "\t\t\t# df_change_filter = df_change_filter[df_change_filter[\"label\"].str.contains(\"?\", regex=False) == False] # change uncomment this line to view (intersection)\n",
    "\t\t\t\n",
    "\t\t\tG = nx.from_pandas_edgelist(df_change_filter, \"source\", \"target\", edge_attr=\"weight1\")\n",
    "\t\t\tnodes = list(G.nodes())\n",
    "\t\t\tdf_nodes_raw = df_join_raw.loc[nodes]\n",
    "\t\t\t\n",
    "\t\t\tnum_nodes_name = len(df_nodes_raw[df_nodes_raw[\"Metabolite name\"] != \"Unknown\"])\n",
    "\t\t\t\n",
    "\t\t\tlist_details.append([method, \"-\".join(group), data_variation, G.number_of_nodes(), G.number_of_edges(), nx.density(G), num_nodes_name])\n",
    "\n",
    "df_details = pd.DataFrame(list_details, columns=[\"Method\", \"Groups\", \"Data var.\", \"Num. nodes\", \"Num. edges\", \"Density\", \"With name\"])\n",
    "df_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details.to_csv(\"z.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# details count labels\n",
    "\n",
    "is_significant = False # change, True: significant changes (*), False: no significant changes (non-* and same labels)\n",
    "\n",
    "list_details = []\n",
    "labels = ['PP', 'Pp', 'PN', 'Pn', 'P?', 'pP', 'pp', 'pN', 'pn', 'p?', 'NP', 'Np', 'NN', 'Nn', 'N?', 'nP', 'np', 'nN', 'nn', 'n?', '?P', '?p', '?N', '?n']\n",
    "\n",
    "for method in methods:\n",
    "\tif method == \"greedy\":\n",
    "\t\tdata_variations = [\"none\"]\n",
    "\telse:\n",
    "\t\tdata_variations = [\"none\", \"str\", \"dyn\"]\n",
    "\tfor data_variation in data_variations:\n",
    "\t\tfor group in groups:\n",
    "\t\t\tdf_change_filter = pd.read_csv(\"experiments/output/{}/changes/changes_edges_log2_{}_{}_{}_{}.csv\".format(exp, method, group[0], group[1], data_variation))\n",
    "\t\t\t\n",
    "\t\t\tif is_significant:\n",
    "\t\t\t\tdf_change_filter = df_change_filter[df_change_filter[\"significant\"] == \"*\"]\n",
    "\t\t\telse:\n",
    "\t\t\t\tdf_change_filter = df_change_filter[df_change_filter[\"significant\"] != \"*\"]\n",
    "\t\t\t\tdf_change_filter = df_change_filter[df_change_filter[\"label\"].isin([\"nn\", \"NN\", \"pp\", \"PP\"])]\n",
    "\t\t\t\t\n",
    "\t\t\tcounts = []\n",
    "\t\t\tfor label in labels:\n",
    "\t\t\t\tcounts.append(len(df_change_filter[df_change_filter.label == label]))\n",
    "\t\t\t\n",
    "\t\t\tlist_details.append([method, \"-\".join(group), data_variation] + counts)\n",
    "\n",
    "df_details = pd.DataFrame(list_details, columns=[\"Method\", \"Groups\", \"Data var.\"] + labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details.to_csv(\"z.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(exp)\n",
    "exp = \"exp201\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "# print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "control = params[\"control\"]\n",
    "print(\"Control:\\t\", control)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_count = []\n",
    "label_x = []\n",
    "label_y = []\n",
    "range_ = range(180, 184) # change\n",
    "\n",
    "for e in range_:\n",
    "\texp = \"exp\" + str(e)\n",
    "\tfile = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "\tparams = json.load(file)\n",
    "\t\n",
    "\tmethods = params[\"methods\"]\n",
    "\t# print(\"Methods:\\t\", methods)\n",
    "\n",
    "\tdata_variations = params[\"data_variations\"]\n",
    "\t# print(\"Data variations:\", data_variations)\n",
    "\t\n",
    "\tdimension = params[\"dimension\"]\n",
    "\t# print(\"Dimension:\", dimension)\n",
    "\t\n",
    "\tgroups_id = params[\"groups_id\"]\n",
    "\t# print(\"Groups id:\\t\", groups_id)\n",
    "\t\n",
    "\tfor i in range(len(data_variations)):\n",
    "\t\tlabel_x = []\n",
    "\t\ttemp = []\n",
    "\t\tfor j in range(len(methods)):\n",
    "\t\t\tfor k in range(len(groups_id)):\n",
    "\t\t\t\t# print(methods[j], groups_id[k], data_variations[i])\n",
    "\t\t\t\tdf_edges_filter_weight_filter = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}.csv\".format(exp, methods[j], groups_id[k], data_variations[i]))\n",
    "\t\t\t\tdf_edges_filter_weight_filter\n",
    "\n",
    "\t\t\t\tG = nx.from_pandas_edgelist(df_edges_filter_weight_filter, source=\"source\", target=\"target\", edge_attr=[\"weight\"], create_using=nx.Graph())\n",
    "\t\t\t\t# graph_partial_detail(G, edges=True)\n",
    "\t\t\t\tSG = G.subgraph([0, 1, 2, 3, 4, 5])\n",
    "\t\t\t\ttemp.append(SG.number_of_edges())\n",
    "\t\t\t\tlabel_x.append(\"{}-{}\".format(methods[j], groups_id[k]))\n",
    "\t\t\n",
    "\t\tlabel_y.append(\"{}-{}-{}\".format(e, data_variations[i], dimension))\n",
    "\t\tedges_count.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Heatmap( \n",
    "\t\t\t\tz=np.array(edges_count).T,\n",
    "\t\t\t\tx=label_y,\n",
    "\t\t\t\ty=label_x,\n",
    "\t\t\t\txgap=1,\n",
    "\t\t\t\tygap=1,\n",
    "\t\t\t\thoverongaps=True,\n",
    "\t\t\t\tcolorscale=\"Plasma\")) # RdBu, Plasma\n",
    "fig = fig.update_traces(text=np.array(edges_count).T, texttemplate=\"%{text}\", hovertemplate=None)\n",
    "fig.update_layout(\n",
    "\tautosize=False,\n",
    "\twidth=30 * len(label_y),\n",
    "\theight=30 * len(label_x),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_num = \"exp155\" # change\n",
    "\n",
    "results = []\n",
    "\n",
    "for group in groups_id:\n",
    "\tdf_common_edges = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}.csv\".format(exp_num, \"greedy\", group, \"none\"))\n",
    "\tG = nx.from_pandas_edgelist(df_common_edges, edge_attr=[\"weight\"])\n",
    "\tresults.append([\"greedy\", group, \"none\", G.number_of_nodes(), G.number_of_edges()])\n",
    "\t\n",
    "for method in methods:\n",
    "\tfor group in groups_id:\n",
    "\t\tfor data_variation in data_variations:\n",
    "\t\t\tdf_common_edges = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}.csv\".format(exp_num, method, group, data_variation))\n",
    "\t\t\tG = nx.from_pandas_edgelist(df_common_edges, edge_attr=[\"weight\"])\n",
    "\t\t\tresults.append([method, group, data_variation, G.number_of_nodes(), G.number_of_edges()])\n",
    "\n",
    "df_results = pd.DataFrame(results, columns=[\"Method\", \"Group\", \"Data var.\", \"Num. nodes\", \"Num. edges\"])\n",
    "# df_results.to_csv(\"experiments/output/{}/common_edges/details.csv\".format(exp), index=False)\n",
    "# df_results.replace(\"greedy\", \"baseline\", inplace=True)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot node-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "exp = \"exp5\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "\n",
    "print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "controls = params[\"controls\"]\n",
    "print(\"Control:\\t\", controls)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def plot_embedding_3d(df_embeddings, labels, reduction=\"pca\", embedding=\"node\", title=\"\", title_legend=\"\", save=False):\n",
    "\t# print(df_embeddings)\n",
    "\t# print(labels)\n",
    "\tif df_embeddings.shape[1] > 3:\n",
    "\t\tif reduction == \"pca\":\n",
    "\t\t\tdf_embeddings_red = PCA(n_components=3).fit_transform(df_embeddings)\n",
    "\t\telif reduction == \"tsne\":\n",
    "\t\t\tdf_embeddings_red = TSNE(n_components=3).fit_transform(df_embeddings)\n",
    "\t\telif reduction == \"umap\":\n",
    "\t\t\tdf_embeddings_red = umap.UMAP().fit_transform(df_embeddings)\n",
    "\telse:\n",
    "\t\tdf_embeddings_red = df_embeddings.values\n",
    "\t\n",
    "\tfig = plt.figure(figsize=(6, 6))\n",
    "\tax = fig.add_subplot(projection=\"3d\")\n",
    "\t\n",
    "\tdf_embeddings = pd.DataFrame(df_embeddings_red)\n",
    "\tdf_embeddings[\"labels\"] = labels.values\n",
    "\t\n",
    "\tunique_labels = np.unique(labels)\n",
    "\tfor i, label in enumerate(unique_labels):\n",
    "\t\tdf_embeddings_filter = df_embeddings[df_embeddings[\"labels\"] == label]\n",
    "\n",
    "\t\tx = df_embeddings_filter.iloc[:, 0]\n",
    "\t\ty = df_embeddings_filter.iloc[:, 1]\n",
    "\t\tz = df_embeddings_filter.iloc[:, 2]\n",
    "\t\t\n",
    "\t\t# new_cmap = matplotlib.colors.ListedColormap(plt.cm.tab10.colors[i: i + 1])\n",
    "\t\tif embedding == \"node\":\n",
    "\t\t\tcolor = matplotlib.colors.ListedColormap(plt.cm.Dark2.colors[i: i + 1]).colors[0]\n",
    "\t\t\t# points = ax.scatter(x, y, z, s=100, c=labels, alpha=0.5, cmap=new_cmap , marker=\".\") # , edgecolors=\"black\", linewidth=0.5)\n",
    "\t\t\tpoints = ax.scatter(x, y, z, s=100, alpha=0.5, color=color, marker=\".\", label=\"Br{}\".format(label + 1))\n",
    "\t\telif embedding == \"edge\":\n",
    "\t\t\tcolor = matplotlib.colors.ListedColormap(plt.cm.Dark2.colors[i: i + 1]).colors[0]\n",
    "\t\t\t# points = ax.scatter(x, y, z, s=100, c=labels, alpha=0.5, cmap=new_cmap , marker=\".\") # , edgecolors=\"black\", linewidth=0.5)\n",
    "\t\t\tpoints = ax.scatter(x, y, z, s=100, alpha=0.5, color=color, marker=\".\", label=\"Br{}\".format(label + 1))\n",
    "\t\telif embedding == \"outlier\":\n",
    "\t\t\t# cmap = matplotlib.colormaps.get_cmap(\"coolwarm\", len(unique_labels))\n",
    "\t\t\tcolors = plt.get_cmap(\"coolwarm\")(np.linspace(0, 1, len(unique_labels)))\n",
    "\t\t\tpoints = ax.scatter(x, y, z, s=100, alpha=0.5, c=[colors[label]], marker=\".\", label=[\"inliers\", \"outliers\"][label]) #, edgecolors=\"black\", linewidth=0.5)\n",
    "\t\n",
    "\t# ax.set_xlabel(\"X\")\n",
    "\t# ax.set_ylabel(\"Y\")\n",
    "\t# ax.set_zlabel(\"Z\")\n",
    "\tif not save:\n",
    "\t\t\"\"\" plt.title(title)\n",
    "\t\tplt.legend(title=title_legend, ncol=1, loc=0, bbox_to_anchor=(1, 0.95)) \"\"\"\n",
    "\t\t# fig.colorbar(points, ax=ax, shrink=0.4, aspect=8) # bar\n",
    "\t\t# ax.legend([\"Biological rep.: {}\".format(subgroup) for subgroup in np.unique(labels)])\n",
    "\t\t# print(*points.legend_elements())\n",
    "\t\t# plt.legend(*points.legend_elements(), bbox_to_anchor=(1.05, 1), loc=2)\n",
    "\tif save:\n",
    "\t\t# plt.legend(title=title_legend, ncol=1, loc=0, bbox_to_anchor=(1, 0.95)) # ncol=len(unique_labels)\n",
    "\t\tplt.savefig(\"experiments/plots/{}.pdf\".format(title), format=\"pdf\", bbox_inches=\"tight\") # change    \n",
    "\tplt.show()\n",
    "\treturn ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "iteration = 1 # change\n",
    "save = False # change\n",
    "\n",
    "for e in [5]: # change, experiment\n",
    "\texp = \"exp\" + str(e)\n",
    "\tfor method in methods[:]: # change\n",
    "\t\tfor group_id in groups_id[:]: # change\n",
    "\t\t\tfor data_variation in data_variations: # change\n",
    "\t\t\t\tdf_node_embeddings_concat = pd.DataFrame()\n",
    "\t\t\t\tif data_variation == \"none\":\n",
    "\t\t\t\t\tk = 0\n",
    "\t\t\t\t\tfor subgroup_id in subgroups_id[group_id]:\n",
    "\t\t\t\t\t\tprint(exp, method, group_id, subgroup_id, iteration)\n",
    "\t\t\t\t\t\tdf_node_embeddings = pd.read_csv(\"experiments/output/{}/node_embeddings/node-embeddings_{}_{}_{}_{}.csv\".format(exp, method, group_id, subgroup_id, iteration), index_col=0)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tdf_node_embeddings[\"subgroup\"] = [k] * len(df_node_embeddings)\n",
    "\t\t\t\t\t\tdf_node_embeddings_concat = pd.concat([df_node_embeddings_concat, df_node_embeddings])\n",
    "\t\t\t\t\t\tk += 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(exp, method, group_id, data_variation, iteration)\n",
    "\t\t\t\t\tdf_nodes = pd.read_csv(\"experiments/output/{}/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(exp, group_id, data_variation), index_col=0, usecols=[0, 1])\n",
    "\t\t\t\t\tdf_nodes[\"subgroup\"] = df_nodes[\"id\"].apply(lambda x: ord(x[0]) - 65)\n",
    "\n",
    "\t\t\t\t\tdf_node_embeddings = pd.read_csv(\"experiments/output/{}/node_embeddings/node-embeddings_{}_{}_{}_{}.csv\".format(exp, method, group_id, data_variation, iteration), index_col=0)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tdf_node_embeddings[\"subgroup\"] = df_nodes[\"subgroup\"]\n",
    "\t\t\t\t\tdf_node_embeddings_concat = pd.concat([df_node_embeddings_concat, df_node_embeddings])\n",
    "\t\t\t\t\n",
    "\t\t\t\tplot_embedding_3d(df_node_embeddings_concat.iloc[:, :-1], df_node_embeddings_concat.iloc[:, -1],\n",
    "\t\t\t\t\t\t\t\t\treduction=\"pca\", embedding=\"node\", title=\"node-embeddings_{}-{}-{}-{}\".format(exp, method, group_id, data_variation), title_legend=\"\", save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot edge-embeddings or outlilers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"exp911\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "control = params[\"control\"]\n",
    "print(\"Control:\\t\", control)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_embeddings_3d_plotly(df_embeddings, color):\n",
    "\tfig = go.Figure(data=[go.Scatter3d(\n",
    "\t\tx=df_embeddings.iloc[:, 0],\n",
    "\t\ty=df_embeddings.iloc[:, 1],\n",
    "\t\tz=df_embeddings.iloc[:, 2],\n",
    "\t\tmode=\"markers\",\n",
    "\t\tmarker=dict(\n",
    "\t\t\tsize=6,\n",
    "\t\t\tcolor=color, # set color to an array/list of desired values\n",
    "\t\t\tcolorscale=\"Portland\",   # choose a colorscale\n",
    "\t\t\topacity=0.8\n",
    "\t\t)\n",
    "\t)])\n",
    "\n",
    "\t# tight layout\n",
    "\tfig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "\tfig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1 # change\n",
    "\n",
    "plot_option = \"outlier\" # change: edge, outlier\n",
    "save = True\n",
    "\n",
    "for e in [911]: # change\n",
    "\texp = \"exp\" + str(e)\n",
    "\tfor method in methods[:]: # change\n",
    "\t\tfor group_id in groups_id[:]: # change\n",
    "\t\t\tfor data_variation in data_variations: # change\n",
    "\t\t\t\tprint(exp, method, group_id, data_variation, iteration)\n",
    "\t\t\t\tdf_edge_embeddings_concat = pd.read_csv(\"experiments/output/{}/edge_embeddings/edge-embeddings_concat_outlier_{}_{}_{}_{}.csv\".format(exp, method, group_id, data_variation, iteration))\n",
    "\t\t\t\t\n",
    "\t\t\t\t# plot without synthetic edges\n",
    "\t\t\t\tdf_edge_embeddings_concat = df_edge_embeddings_concat[df_edge_embeddings_concat[\"subgroup\"] != -1]\n",
    "\t\t\t\t\n",
    "\t\t\t\tif plot_option == \"edge\":\n",
    "\t\t\t\t\t# edge-embeddings\n",
    "\t\t\t\t\tplot_embedding_3d(df_edge_embeddings_concat.iloc[:, 2:-2], df_edge_embeddings_concat.iloc[:, -2],\n",
    "\t\t\t\t\t\t\t\t\treduction=\"pca\", embedding=plot_option, title=\"edge-embeddings_{}-{}-{}-{}\".format(exp, method, group_id, data_variation), title_legend=\"\", save=save)\n",
    "\t\t\t\telif  plot_option == \"outlier\":\n",
    "\t\t\t\t\t# outliers\n",
    "\t\t\t\t\tplot_embedding_3d(df_edge_embeddings_concat.iloc[:, 2:-2], df_edge_embeddings_concat.iloc[:, -1],\n",
    "\t\t\t\t\t\t\t\t\t\treduction=\"pca\", embedding=plot_option, title=\"outliers_{}-{}-{}-{}\".format(exp, method, group_id, data_variation), title_legend=\"\", save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(exp)\n",
    "exp = \"exp1101\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "# print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "control = params[\"control\"]\n",
    "print(\"Control:\\t\", control)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_count = []\n",
    "label_x = []\n",
    "label_y = []\n",
    "runtime_node_embedding = np.zeros(len(methods) * 3)\n",
    "runtime_edge_embedding = np.zeros(len(methods) * 3)\n",
    "\n",
    "dimensions = [2, 3, 4, 8, 16, 32, 64, 128, 256, 512] # change [3, 4, 8, 16, 32, 64, 128, 256, 512]\n",
    "iterations = 10 # change 1, 3, 5, 10\n",
    "range_ = range(1101, 1201) # change exp\n",
    "k = 0\n",
    "df_runtimes = pd.DataFrame()\n",
    "\n",
    "for i, e in enumerate(range_, 1):\n",
    "\texp = \"exp\" + str(e)\n",
    "\tdf_process = pd.read_csv(\"experiments/output/{}/common_edges/runtimes.csv\".format(exp))\n",
    "\truntime_node_embedding += df_process[\"Runtime node embedding\"]\n",
    "\truntime_edge_embedding += df_process[\"Runtime edge embedding\"]\n",
    "\t\n",
    "\tif i % iterations == 0:\n",
    "\t\truntime_node_embedding = runtime_node_embedding / iterations\n",
    "\t\truntime_edge_embedding = runtime_edge_embedding / iterations\n",
    "\t\t# print(runtime_node_embedding)        \n",
    "\t\tdf_runtimes.insert(k, \"Node embedding ({})\".format(dimensions[k]), runtime_node_embedding)\n",
    "\t\tdf_runtimes[\"Edge embedding ({})\".format(dimensions[k])] = runtime_edge_embedding\n",
    "\t\t\n",
    "\t\tk += 1\n",
    "\t\truntime_node_embedding = np.zeros(len(methods) * 3)\n",
    "\t\truntime_edge_embedding = np.zeros(len(methods) * 3)\n",
    "\t\t\n",
    "df_runtimes.insert(0, \"Method\", df_process[\"Method\"])\n",
    "df_runtimes.insert(1, \"Data variation\", df_process[\"Data variation\"])\n",
    "df_runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes + edges\n",
    "\"\"\" fig = go.Figure(data=go.Heatmap( \n",
    "\tz=df_runtimes.iloc[:, 2:],\n",
    "\tx=df_runtimes.iloc[:, 2:].columns,\n",
    "\ty=df_runtimes[\"Method\"] + \"-\" +  df_runtimes[\"Data variation\"],\n",
    "\txgap=1,\n",
    "\tygap=1,\n",
    "\thoverongaps=True,\n",
    "\tcolorscale=\"Plasma\")) # RdBu, Plasma\n",
    "fig = fig.update_traces(text=df_runtimes.iloc[:, 2:].round(2), texttemplate=\"%{text}\", hovertemplate=None)\n",
    "fig.update_layout(\n",
    "\tautosize=False,\n",
    "\twidth=60 * len(df_runtimes.iloc[:, 2:].columns),\n",
    "\theight=30 * len(df_runtimes[\"Method\"]),\n",
    ")\n",
    "fig.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.log10, validate=True) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, shared_yaxes=False)\n",
    "\n",
    "fig.add_trace(\n",
    "\tgo.Heatmap( \n",
    "\t\tz=transformer.transform(df_runtimes.iloc[:, 2:9]),\n",
    "\t\tx=df_runtimes.iloc[:, 2:9].columns,\n",
    "\t\ty=df_runtimes[\"Method\"] + \"-\" +  df_runtimes[\"Data variation\"],\n",
    "\t\txgap=1,\n",
    "\t\tygap=1,\n",
    "\t\thoverongaps=True),\n",
    "\trow=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "\tgo.Heatmap( \n",
    "\t\tz=df_runtimes.iloc[:, 9:],\n",
    "\t\tx=df_runtimes.iloc[:, 9:].columns,\n",
    "\t\ty=df_runtimes[\"Method\"] + \"-\" +  df_runtimes[\"Data variation\"],\n",
    "\t\txgap=1,\n",
    "\t\tygap=1,\n",
    "\t\thoverongaps=True),\n",
    "\trow=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(height=600, width=1000, title_text=\"Side By Side Subplots\")\n",
    "# fig.update_layout(coloraxis=dict(colorscale='Bluered_r'), showlegend=False)\n",
    "fig.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtimes = df_runtimes[df_runtimes[\"Method\"].isin([\"dgi-tran\", \"argva-base\", \"vgae-line\", \"vgae-base\"])]\n",
    "df_runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtimes.to_csv(\"experiments/run_details/runtimes_synthetic_random.csv\") # change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z = transformer.transform(df_runtimes.iloc[:, 2:].values)\n",
    "z = df_runtimes.iloc[:, 2:].values\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodes\n",
    "\"\"\" fig = go.Figure(data=go.Heatmap( \n",
    "\t\tz=z[:, :7], # change 5, 7\n",
    "\t\tx=df_runtimes.iloc[:, 2:9].columns, # change 2:7, 2:9\n",
    "\t\ty=df_runtimes[\"Method\"] + \"-\" +  df_runtimes[\"Data variation\"],\n",
    "\t\txgap=1,\n",
    "\t\tygap=1,\n",
    "\t\thoverongaps=True,\n",
    "\t\tcolorscale=\"Plasma\")) # RdBu, Plasma\n",
    "fig = fig.update_traces(text=np.round(z[:, :7], decimals=2), texttemplate=\"%{text}\", hovertemplate=None) # change 5, 7\n",
    "fig.update_layout(\n",
    "\tautosize=False,\n",
    "\twidth=90 * len(df_runtimes.iloc[:, 2:9].columns), # change 2:7, 2:9\n",
    "\theight=40 * len(df_runtimes[\"Method\"]),\n",
    ")\n",
    "fig.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runtimes[\"Method\"] = [\"DGI\"] * 3 + [\"ARGVA\"] * 3 + [\"LVGAE\"] * 3 + [\"VGAE\"] * 3\n",
    "df_runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edges\n",
    "\"\"\" fig = go.Figure(data=go.Heatmap( \n",
    "\t\tz=z[:, 7:], # change 5, 7\n",
    "\t\tx=df_runtimes.iloc[:, 9:].columns, # change 7, 9\n",
    "\t\ty=df_runtimes[\"Method\"] + \"-\" +  df_runtimes[\"Data variation\"],\n",
    "\t\txgap=1,\n",
    "\t\tygap=1,\n",
    "\t\thoverongaps=True,\n",
    "\t\tcolorscale=\"Plasma\")) # RdBu, Plasma\n",
    "fig = fig.update_traces(text=np.round(z[:, 7:], decimals=2), texttemplate=\"%{text}\", hovertemplate=None) # change 5, 7\n",
    "fig.update_layout(\n",
    "\tautosize=False,\n",
    "\twidth=90 * len(df_runtimes.iloc[:, 9:].columns), # change 7, 9\n",
    "\theight=40 * len(df_runtimes[\"Method\"]),\n",
    ")\n",
    "fig.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtimes node-embeddings\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "colors = [\"#FF00FF\", \"#3FFF00\", \"#00FFFF\", \"#FFF700\", \"#FF0000\", \"#0000FF\", \"#006600\", \n",
    "\t'#00CC96', '#AB63FA', '#FFA15A', '#19D3F3', '#FF6692', '#B6E880', '#FF97FF', 'black',\"gray\"]\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "k = 0\n",
    "\n",
    "x = [\"2\", \"3\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\", \"256\", \"512\"] # change [\"3\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"]\n",
    "end = 10 # change 5:32, 7:128, 10: 512\n",
    "name = \"mutant_random\" # change\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "for i in range(0, len(df_runtimes), 3):\n",
    "\t# print(df_runtimes.iloc[i, :].values)\n",
    "\n",
    "\tplt.plot(x, z[i, :end], label=\"{}-{}\".format(df_runtimes.iloc[i, 0], df_runtimes.iloc[i, 1]), linestyle=\"-\", color=colors[k], linewidth=1)\n",
    "\tplt.plot(x, z[i + 1, :end], label=\"{}-{}\".format(df_runtimes.iloc[i + 1, 0], df_runtimes.iloc[i + 1, 1]), linestyle=\"--\", color=colors[k], linewidth=1)\n",
    "\tplt.plot(x, z[i + 2, 0:end], label=\"{}-{}\".format(df_runtimes.iloc[i + 2, 0], df_runtimes.iloc[i + 2, 1]), linestyle=\":\", color=colors[k], linewidth=1)\n",
    "\tk += 1\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1, 0.45), loc='upper right', fontsize=\"9\", ncol=2) # cancer\n",
    "# plt.legend(bbox_to_anchor=(1, 0.9), loc='upper right', fontsize=\"9\", ncol=2) # mutant\n",
    "\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Runtimes (sec.)\")\n",
    "\n",
    "plt.savefig(\"experiments/plots/runtimes_node_embeddings_{}.pdf\".format(name), format=\"pdf\", bbox_inches=\"tight\") # change\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runtimes edge-embeddings\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "colors = [\"#FF00FF\", \"#3FFF00\", \"#00FFFF\", \"#FFF700\", \"#FF0000\", \"#0000FF\", \"#006600\", \n",
    "\t'#00CC96', '#AB63FA', '#FFA15A', '#19D3F3', '#FF6692', '#B6E880', '#FF97FF', 'black',\"gray\"]\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "k = 0\n",
    "\n",
    "x = [\"2\", \"3\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\", \"256\", \"512\"] # change [\"3\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\", \"256\", \"512\"]\n",
    "end = 10 # change 5:32, 7:128, 10: 512\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "for i in range(0, len(df_runtimes), 3):\n",
    "\t# print(df_runtimes.iloc[i, :].values)\n",
    "\n",
    "\tplt.plot(x, z[i, end:], label=\"{}-{}\".format(df_runtimes.iloc[i, 0], df_runtimes.iloc[i, 1]), linestyle=\"-\", color=colors[k], linewidth=1)\n",
    "\tplt.plot(x, z[i + 1, end:], label=\"{}-{}\".format(df_runtimes.iloc[i + 1, 0], df_runtimes.iloc[i + 1, 1]), linestyle=\"--\", color=colors[k], linewidth=1)\n",
    "\tplt.plot(x, z[i + 2, end:], label=\"{}-{}\".format(df_runtimes.iloc[i + 2, 0], df_runtimes.iloc[i + 2, 1]), linestyle=\":\", color=colors[k], linewidth=1)\n",
    "\tk += 1\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1, 1.02), ncol=1)\n",
    "plt.legend(fontsize=\"9\", ncol=2)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Dimensions\")\n",
    "plt.ylabel(\"Runtimes (sec.)\")\n",
    "\n",
    "plt.savefig(\"experiments/plots/runtimes_edge_embeddings_{}.pdf\".format(name), format=\"pdf\", bbox_inches=\"tight\") # change\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average count nodes/edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_count = []\n",
    "label_x = []\n",
    "label_y = []\n",
    "range_ = range(1101, 1201) # change\n",
    "\n",
    "for e in range_:\n",
    "\texp = \"exp\" + str(e)\n",
    "\tfile = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "\tparams = json.load(file)\n",
    "\t\n",
    "\tmethods = params[\"methods\"]\n",
    "\t# print(\"Methods:\\t\", methods)\n",
    "\n",
    "\tdata_variations = params[\"data_variations\"]\n",
    "\t# print(\"Data variations:\", data_variations)\n",
    "\t\n",
    "\tdimension = params[\"dimension\"]\n",
    "\t# print(\"Dimension:\", dimension)\n",
    "\t\n",
    "\tgroups_id = params[\"groups_id\"]\n",
    "\t# print(\"Groups id:\\t\", groups_id)\n",
    "\t\n",
    "\tfor i in range(len(data_variations)):\n",
    "\t\tlabel_x = []\n",
    "\t\ttemp = []\n",
    "\t\tfor j in range(len(methods)):\n",
    "\t\t\tfor k in range(len(groups_id)):\n",
    "\t\t\t\t# print(methods[j], groups_id[k], data_variations[i])\n",
    "\t\t\t\tdf_edges_filter_weight_filter = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}.csv\".format(exp, methods[j], groups_id[k], data_variations[i]))\n",
    "\t\t\t\tdf_edges_filter_weight_filter\n",
    "\n",
    "\t\t\t\tG = nx.from_pandas_edgelist(df_edges_filter_weight_filter, source=\"source\", target=\"target\", edge_attr=[\"weight\"], create_using=nx.Graph())\n",
    "\t\t\t\t# graph_partial_detail(G, edges=True)\n",
    "\t\t\t\t# SG = G.subgraph([0, 1, 2, 3, 4, 5])\n",
    "\t\t\t\ttemp.append(G.number_of_edges())\n",
    "\t\t\t\tlabel_x.append(\"{}-{}\".format(methods[j], groups_id[k]))\n",
    "\t\t\n",
    "\t\tlabel_y.append(\"{}-{}-{}\".format(e, data_variations[i], dimension))\n",
    "\t\tedges_count.append(temp)\n",
    "\n",
    "df_edges_count = pd.DataFrame(np.array(edges_count).T, index=label_x, columns=label_y)\n",
    "df_edges_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" fig = go.Figure(data=go.Heatmap( \n",
    "\t\t\t\tz=df_edges_count.values,\n",
    "\t\t\t\tx=df_edges_count.columns,\n",
    "\t\t\t\ty=df_edges_count.index,\n",
    "\t\t\t\txgap=1,\n",
    "\t\t\t\tygap=1,\n",
    "\t\t\t\thoverongaps=True,\n",
    "\t\t\t\tcolorscale=\"Plasma\")) # RdBu, Plasma\n",
    "fig = fig.update_traces(text=df_edges_count.values, texttemplate=\"%{text}\", hovertemplate=None)\n",
    "fig.update_layout(\n",
    "\tautosize=False,\n",
    "\twidth=60 * len(df_edges_count.columns),\n",
    "\theight=30 * len(df_edges_count.index),\n",
    ")\n",
    "fig.show() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average\n",
    "\n",
    "df_edges_count_avg = pd.DataFrame()\n",
    "dimensions = [2, 3, 4, 8, 16, 32, 64, 128, 256, 512] # change 3, 4, 8, 16, 32, 64, 128, 256, 512\n",
    "iterations = 10 # change 3, 5, 10\n",
    "k = 0\n",
    "\n",
    "a = np.zeros(len(methods) * len(groups_id))\n",
    "b = np.zeros(len(methods) * len(groups_id))\n",
    "c = np.zeros(len(methods) * len(groups_id))\n",
    "\n",
    "for i in range(1, len(df_edges_count.columns) + 1, 3):\n",
    "\t# print(i - 1, i, i + 1)\n",
    "\ta += df_edges_count.iloc[:, i - 1]\n",
    "\tb += df_edges_count.iloc[:, i]\n",
    "\tc += df_edges_count.iloc[:, i + 1]\n",
    "\t\n",
    "\tif (i + 2) % (3 * iterations) == 0:\n",
    "\t\ta = a / iterations\n",
    "\t\tb = b / iterations\n",
    "\t\tc = c / iterations\n",
    "\t\t# print(k)\n",
    "\t\tdf_edges_count_avg[\"none-{}\".format(dimensions[k])] = a\n",
    "\t\tdf_edges_count_avg[\"str-{}\".format(dimensions[k])] = b\n",
    "\t\tdf_edges_count_avg[\"dyn-{}\".format(dimensions[k])] = c\n",
    "\t\t\n",
    "\t\tk += 1\n",
    "\t\ta = np.zeros(len(methods) * len(groups_id))\n",
    "\t\tb = np.zeros(len(methods) * len(groups_id))\n",
    "\t\tc = np.zeros(len(methods) * len(groups_id))\n",
    "\n",
    "df_edges_count_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "df_edges_count_avg.to_csv(\"experiments/run_details/edges_avg_synthetic_random.csv\") # change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" fig = go.Figure(data=go.Heatmap( \n",
    "\t\t\t\tz=df_edges_count_avg.values,\n",
    "\t\t\t\tx=df_edges_count_avg.columns,\n",
    "\t\t\t\ty=df_edges_count_avg.index,\n",
    "\t\t\t\txgap=1,\n",
    "\t\t\t\tygap=1,\n",
    "\t\t\t\thoverongaps=True,\n",
    "\t\t\t\tcolorscale=\"Plasma\")) # RdBu, Plasma\n",
    "fig = fig.update_traces(text=df_edges_count_avg.round(0).values, texttemplate=\"%{text}\", hovertemplate=None)\n",
    "fig.update_layout(\n",
    "\tautosize=False,\n",
    "\twidth=60 * len(df_edges_count_avg.columns),\n",
    "\theight=40 * len(df_edges_count_avg.index),\n",
    ")\n",
    "fig.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges_count_avg.iloc[0::3, :].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get values by properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number edges by properties (mutant, cancer)\n",
    "\n",
    "a = df_edges_count_avg.iloc[0::3, :].round(2).values # pck1\n",
    "b = df_edges_count_avg.iloc[1::3, :].round(2).values # zwf1\n",
    "c = df_edges_count_avg.iloc[2::3, :].round(2).values # WT\n",
    "print(a.tolist())\n",
    "print(b.tolist())\n",
    "print(c.tolist())\n",
    "print()\n",
    "\n",
    "# add greedy\n",
    "\"\"\" a = np.insert(a, len(a), [73]*len(a[0]), axis=0)\n",
    "b = np.insert(b, len(b), [1777]*len(b[0]), axis=0)\n",
    "c = np.insert(c, len(c), [5]*len(c[0]), axis=0)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number edges by properties (new cancer)\n",
    "\n",
    "a = df_edges_count_avg.iloc[0::9, :].round(2).values \n",
    "b = df_edges_count_avg.iloc[1::9, :].round(2).values\n",
    "c = df_edges_count_avg.iloc[2::9, :].round(2).values\n",
    "print(a.tolist())\n",
    "print(b.tolist())\n",
    "print(c.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number edges by properties (leaf, synthetic)\n",
    "\n",
    "a = df_edges_count_avg.iloc[0::2, :].round(2).values # new\n",
    "b = df_edges_count_avg.iloc[1::2, :].round(2).values # old\n",
    "print(a.tolist())\n",
    "print(b.tolist())\n",
    "\n",
    "# add greedy\n",
    "\"\"\" a = np.insert(a, len(a), [8365]*len(a[0]), axis=0)\n",
    "b = np.insert(b, len(b), [7618]*len(b[0]), axis=0)\n",
    "print(a)\n",
    "print(b) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutant, cancer, leaf, synthetic\n",
    "columns = [\"none-2\", \"str-2\", \"dyn-2\", \"none-3\", \"str-3\", \"dyn-3\", \"none-4\", \"str-4\", \"dyn-4\", \"none-8\", \"str-8\", \"dyn-8\", \"none-16\", \"str-16\", \"dyn-16\", \"none-32\",\n",
    "\t\t\t\"str-32\", \"dyn-32\", \"none-64\", \"str-64\", \"dyn-64\", \"none-128\", \"str-128\", \"dyn-128\", \"none-256\", \"str-256\", \"dyn-256\", \"none-512\", \"str-512\", \"dyn-512\"]\n",
    "\n",
    "row1 = [\"DGI\", \"ARGVA\", \"LVGAE\", \"VGAE\"] #, \"Greedy\"]\n",
    "row2 = [\"DGI\", \"ARGVA\", \"LVGAE\", \"VGAE\"] #, \"Greedy\"]\n",
    "row3 = [\"DGI\", \"ARGVA\", \"LVGAE\", \"VGAE\"] #, \"Greedy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutant, reinhard\n",
    "\"\"\" import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ax1 = plt.subplot(3, 1, 1)\n",
    "ax1.set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "ax1.set_yticks(np.arange(len(row1)), labels=row1)\n",
    "plt.imshow(a, cmap=\"coolwarm_r\")\n",
    "\n",
    "ax2 = plt.subplot(3 ,1, 2)\n",
    "ax2.set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "ax2.set_yticks(np.arange(len(row2)), labels=row2)\n",
    "plt.imshow(b, cmap=\"coolwarm_r\")\n",
    "\n",
    "ax3 = plt.subplot(3 ,1, 3)\n",
    "ax3.set_xticks(np.arange(len(columns)), labels=columns)\n",
    "ax3.set_yticks(np.arange(len(row3)), labels=row3)\n",
    "plt.setp(ax3.get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.imshow(c, cmap=\"coolwarm_r\")\n",
    "\n",
    "# plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "cax = plt.axes((0.92, 0.265, 0.02, 0.468)) # mutant\n",
    "# cax = plt.axes((0.854, 0.265, 0.02, 0.468)) # reinhard\n",
    "plt.colorbar(cax=cax)\n",
    "\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutant, reinhard\n",
    "\n",
    "\"\"\" import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(6, 3))\n",
    "# plt.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0.2, hspace=0.4)\n",
    "# fig.tight_layout()\n",
    "\n",
    "ax = axs[0]\n",
    "pcm = ax.pcolormesh(a, cmap=\"coolwarm_r\")\n",
    "ax.set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "ax.set_yticks(np.arange(len(row1)), labels=row1)\n",
    "\n",
    "ax = axs[1]\n",
    "pcm = ax.pcolormesh(b, cmap=\"coolwarm_r\")\n",
    "ax.set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "ax.set_yticks(np.arange(len(row2)), labels=row2)\n",
    "\n",
    "ax = axs[2]\n",
    "pcm = ax.pcolormesh(c, cmap=\"coolwarm_r\")\n",
    "ax.set_xticks(np.arange(len(columns)), labels=columns)\n",
    "ax.set_yticks(np.arange(len(row3)), labels=row3)\n",
    "plt.setp(ax.get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "fig.colorbar(pcm, ax=axs[:], shrink=0.6)\n",
    "# plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "# cax = plt.axes((0.92, 0.265, 0.02, 0.468)) # mutant\n",
    "# cax = plt.axes((0.854, 0.265, 0.02, 0.468)) # reinhard\n",
    "# plt.colorbar(cax=cax)\n",
    "\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace outliers values\n",
    "\n",
    "\"\"\" print(a)\n",
    "b[3][1] = b.min()\n",
    "b[3][2] = b.min()\n",
    "print(a) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a.min(), a.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutant and cancer (Heatmap)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "name = \"mutant_random\"\n",
    "# Create a figure and subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 4.5)) # mutant\n",
    "# Adjust layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Plot the first image\n",
    "ax0 = axes[2].imshow(a, cmap=\"Blues\", interpolation=\"none\", vmin=round(a.min()), vmax=round(a.max()))\n",
    "axes[2].set_xticks(np.arange(len(columns)), labels=columns)\n",
    "axes[2].set_yticks(np.arange(len(row1)), labels=row1)\n",
    "axes[2].set_title(\"pck1\")\n",
    "plt.setp(axes[2].get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "# axes[0].axis('off')\n",
    "cbar = fig.colorbar(ax0, ax=axes[2], ticks=[round(a.min()), round((a.min() + a.max()) / 2), round(a.max())], pad=0.01)\n",
    "cbar.set_label(\"Num. edges\")\n",
    "\n",
    "# Plot the second image\n",
    "ax1 = axes[1].imshow(b, cmap=\"Blues\", interpolation=\"none\", vmin=round(b.min()), vmax=round(b.max()))\n",
    "axes[1].set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "axes[1].set_yticks(np.arange(len(row2)), labels=row2)\n",
    "axes[1].set_title(\"zwf1\")\n",
    "# axes[1].axis('off')\n",
    "cbar = fig.colorbar(ax1, ax=axes[1], ticks=[round(b.min()), round((b.min() + b.max()) / 2), round(b.max())], pad=0.01)\n",
    "cbar.set_label(\"Num. edges\")\n",
    "\n",
    "# Plot the third image\n",
    "ax2 = axes[0].imshow(c, cmap=\"Blues\", interpolation=\"none\", vmin=round(c.min()), vmax=round(c.max()))\n",
    "axes[0].set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "axes[0].set_yticks(np.arange(len(row3)), labels=row3)\n",
    "axes[0].set_title(\"WT\")\n",
    "# axes[2].axis('off')\n",
    "cbar = fig.colorbar(ax2, ax=axes[0], ticks=[round(c.min()), round((c.min() + c.max()) / 2), round(c.max())], pad=0.01)\n",
    "cbar.set_label(\"Num. edges\")\n",
    "\n",
    "# Create a single colorbar for all subplots\n",
    "# cbar = fig.colorbar(ax2, ax=axes.ravel().tolist(), fraction=0.02, pad=0.02)\n",
    "# cbar.set_label(\"Num. of common edges\")\n",
    "\n",
    "\"\"\" cax = plt.axes((0.888, 0.11, 0.02, 0.77)) # change mutant\n",
    "# cax = plt.axes((0.735, 0.11, 0.02, 0.77)) # change cancer\n",
    "cbar = fig.colorbar(ax1, cax=cax)\n",
    "cbar.set_label(\"Common edges\") \"\"\"\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"experiments/plots/common_edges_{}.pdf\".format(name), format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutant and cancer (Line)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 10)) # mutant\n",
    "# Adjust layout\n",
    "# plt.tight_layout()\n",
    "x = np.arange(len(columns))\n",
    "for i, y in enumerate(a):\n",
    "  # Plot the first image\n",
    "  ax0 = axes[0].plot(x, y, label=row1[i], marker=\".\")\n",
    "axes[0].set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "  # axes[0].set_yticks(np.arange(len(row1)), labels=row1)\n",
    "axes[0].set_title(\"pck1\")\n",
    "axes[0].set_ylabel(\"# edges\")\n",
    "# axes[0].axis('off')\n",
    "\n",
    "# Plot the second image\n",
    "for i, y in enumerate(b):\n",
    "  ax1 = axes[1].plot(x, y, label=row2[i], marker=\".\")\n",
    "axes[1].set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "  # axes[1].set_yticks(np.arange(len(row2)), labels=row2)\n",
    "axes[1].set_title(\"zwf1\")\n",
    "axes[1].set_ylabel(\"# edges\")\n",
    "# axes[1].axis('off')\n",
    "\n",
    "# Plot the third image\n",
    "for i, y in enumerate(c):\n",
    "  ax2 = axes[2].plot(x, y, label=row3[i], marker=\".\")\n",
    "axes[2].set_xticks(np.arange(len(columns)), labels=columns)\n",
    "# axes[2].set_yticks(np.arange(len(row3)), labels=row3)\n",
    "plt.setp(axes[2].get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "axes[2].set_title(\"WT\")\n",
    "axes[2].set_ylabel(\"# edges\")\n",
    "# axes[2].axis('off')\n",
    "\n",
    "# Create a single colorbar for all subplots\n",
    "# cbar = fig.colorbar(ax2, ax=axes.ravel().tolist(), fraction=0.02, pad=0.02)\n",
    "# cbar.set_label(\"Num. of common edges\")\n",
    "\n",
    "\"\"\" cax = plt.axes((0.888, 0.11, 0.02, 0.77)) # change mutant\n",
    "# cax = plt.axes((0.735, 0.11, 0.02, 0.77)) # change cancer\n",
    "cbar = fig.colorbar(ax1, cax=cax)\n",
    "cbar.set_label(\"Common edges\") \"\"\"\n",
    "plt.legend() \n",
    "# Show the plot\n",
    "plt.savefig(\"experiments/plots/common_edges_mutant.pdf\", format=\"pdf\", bbox_inches=\"tight\") # change\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaf\n",
    "\n",
    "\"\"\" import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "ax1 = plt.subplot(3, 1, 1)\n",
    "ax1.set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "ax1.set_yticks(np.arange(len(row1)), labels=row1)\n",
    "plt.imshow(a, cmap=\"coolwarm_r\")\n",
    "\n",
    "ax2 = plt.subplot(3 ,1, 2)\n",
    "ax2.set_xticks(np.arange(len(columns)), labels=columns)\n",
    "ax2.set_yticks(np.arange(len(row2)), labels=row2)\n",
    "plt.setp(ax2.get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.imshow(b, cmap=\"coolwarm_r\")\n",
    "\n",
    "# plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "cax = plt.axes((0.92, 0.397, 0.02, 0.468))\n",
    "plt.colorbar(cax=cax)\n",
    "\n",
    "plt.show() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaf, sythetic (Heatmap)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "name = \"synthetic_random_remove\" # change\n",
    "# Create a figure and subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 3))\n",
    "# Adjust layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Plot the first image\n",
    "ax0 = axes[0].imshow(a, cmap=\"Blues\", interpolation=\"none\", vmin=round(a.min()), vmax=round(a.max()))\n",
    "axes[0].set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "axes[0].set_yticks(np.arange(len(row1)), labels=row1)\n",
    "axes[0].set_title(\"phenotype1\") # phenotype1, new\n",
    "# axes[0].axis('off')\n",
    "cbar = fig.colorbar(ax0, ax=axes[0], ticks=[round(a.min()), round((a.min() + a.max()) / 2), round(a.max())], pad=0.01)\n",
    "cbar.set_label(\"Num. edges\")\n",
    "\n",
    "# Plot the third image\n",
    "ax1 = axes[1].imshow(b, cmap=\"Blues\", interpolation=\"none\", vmin=round(b.min()), vmax=round(b.max()))\n",
    "axes[1].set_xticks(np.arange(len(columns)), labels=columns)\n",
    "axes[1].set_yticks(np.arange(len(row2)), labels=row2)\n",
    "plt.setp(axes[1].get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "axes[1].set_title(\"phenotype2\") # phenotype2, old\n",
    "# axes[1].axis('off')\n",
    "cbar = fig.colorbar(ax1, ax=axes[1], ticks=[round(b.min()), round((b.min() + b.max()) / 2), round(b.max())], pad=0.01)\n",
    "cbar.set_label(\"Num. edges\")\n",
    "\n",
    "# Create a single colorbar for all subplots\n",
    "# cbar = fig.colorbar(ax1, ax=axes.ravel().tolist(), fraction=0.02, pad=0.02, shrink=1)\n",
    "# cbar.set_label(\"Num. of common edges\")\n",
    "\n",
    "\"\"\" cax = plt.axes((0.873, 0.11, 0.02, 0.77))\n",
    "cbar = fig.colorbar(ax1, cax=cax)\n",
    "cbar.set_label(\"Common edges\") \"\"\"\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"experiments/plots/common_edges_{}.pdf\".format(name), format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mutant\" # change\n",
    "\n",
    "list_df_edges = []\n",
    "\n",
    "df_edges_count_avg = pd.read_csv(\"experiments/run_details/edges_avg_{}.csv\".format(dataset), index_col=0)\n",
    "\n",
    "a = df_edges_count_avg.iloc[0::3, :].round(2) # pck1\n",
    "b = df_edges_count_avg.iloc[1::3, :].round(2) # zwf1\n",
    "c = df_edges_count_avg.iloc[2::3, :].round(2) # WT\n",
    "\n",
    "list_df_edges.append(a)\n",
    "list_df_edges.append(b)\n",
    "list_df_edges.append(c)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"leaf\" # change\n",
    "\n",
    "df_edges_count_avg = pd.read_csv(\"experiments/run_details/edges_avg_{}.csv\".format(dataset), index_col=0)\n",
    "\n",
    "a = df_edges_count_avg.iloc[0::2, :].round(2) # new\n",
    "b = df_edges_count_avg.iloc[1::2, :].round(2) # old\n",
    "\n",
    "list_df_edges.append(a)\n",
    "list_df_edges.append(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"synthetic\" # change\n",
    "\n",
    "df_edges_count_avg = pd.read_csv(\"experiments/run_details/edges_avg_{}.csv\".format(dataset), index_col=0)\n",
    "\n",
    "a = df_edges_count_avg.iloc[0::2, :].round(2) # p1\n",
    "b = df_edges_count_avg.iloc[1::2, :].round(2) # p2\n",
    "\n",
    "list_df_edges.append(a)\n",
    "list_df_edges.append(b)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "X_sum = np.zeros(list_df_edges[0].shape)\n",
    "\n",
    "for df_edge in list_df_edges:\n",
    "\tX_train = df_edge.values\n",
    "\tmin_max_scaler = preprocessing.MinMaxScaler() # MinMaxScaler(), MaxAbsScaler()\n",
    "\tX_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "\tX_sum = X_sum + X_train_minmax\n",
    "\n",
    "X_avg = X_sum / len(list_df_edges)\n",
    "X_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = pd.DataFrame(X_avg, index=[\"DGI\", \"ARGVA\", \"LVGAE\", \"VGAE\"])\n",
    "df_avg\n",
    "\n",
    "df_avg.T.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count metabolities with name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(exp)\n",
    "exp = \"exp3\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "# print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "control = params[\"control\"]\n",
    "print(\"Control:\\t\", control)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_raw = pd.read_csv(\"experiments/input/{}_raw.csv\".format(exp), index_col=0, usecols=[0, 1, 2])        \n",
    "# df_join_raw.columns = [\"mz\", \"name\"]\n",
    "df_join_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count metabolities by name\n",
    "size1_ = len(df_join_raw)\n",
    "size2_ = len(df_join_raw[df_join_raw[\"Metabolite name\"] != \"Unknown\"])\n",
    "\t\t\t\n",
    "names_details = []\n",
    "for method in methods: # change\n",
    "\tfor group_id in groups_id: # change\n",
    "\t\tfor data_variation in data_variations: # change\n",
    "\t\t\t# read edges\n",
    "\t\t\tdf_edges = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}.csv\".format(exp, method, group_id, data_variation))\n",
    "\t\t\t# print(method, data_variation, group_id)\n",
    "\t\t\tunique_nodes = np.unique(np.sort(df_edges[[\"source\", \"target\"]], axis=None)) # np.sort(np.unique(df_edges[[\"source\", \"target\"]].values.flatten()))\n",
    "\t\t\t# print(unique_nodes)\n",
    "\t\t\tdf_nodes_raw = df_join_raw.loc[unique_nodes]\n",
    "\t\t\t# print(df_nodes_raw)\n",
    "\t\t\t\n",
    "\t\t\tsize1 = len(df_nodes_raw)\n",
    "\t\t\tsize2 = len(df_nodes_raw[df_nodes_raw[\"Metabolite name\"] != \"Unknown\"])\n",
    "\t\t\t\n",
    "\t\t\tnames_details.append([method, group_id, data_variation, size1_, size2_, size1, size2])\n",
    "\n",
    "df_names_details = pd.DataFrame(names_details, columns=[\"Method\", \"Group\", \"Data var.\", \"Raw-nodes\", \"Raw-nodes-name\", \"Filter-nodes\", \"Filter-nodes-name\"])\n",
    "df_names_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(exp)\n",
    "exp = \"exp22\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "# print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "control = params[\"control\"]\n",
    "print(\"Control:\\t\", control)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "method = methods[0] # change\n",
    "print(method)\n",
    "data_variation = data_variations[2] # change\n",
    "print(data_variation)\n",
    "group = groups[0] # change\n",
    "print(group)\n",
    "\n",
    "df_join_raw = pd.read_csv(\"experiments/input/{}_raw.csv\".format(exp), index_col=0, usecols=[0, 1, 2])        \n",
    "# df_join_raw.columns = [\"mz\", \"name\"]\n",
    "df_join_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "df_change = pd.read_csv(\"experiments/output/{}/changes/changes_edges_log2_{}_{}_{}_{}.csv\".format(exp, method, group[0], group[1], data_variation))\n",
    "# G = nx.from_pandas_edgelist(df_change_filter, edge_attr=[\"label\"], create_using=nx.DiGraph())\n",
    "df_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df_change[\"significant\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df_change[((df_change[\"significant\"] == \"*\"))]\n",
    "d[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = df_change[((df_change[\"significant\"] != \"*\"))]\n",
    "d[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new filter\n",
    "\n",
    "\"\"\" df_change_filter = df_change[((df_change[\"significant\"] == \"*\") & (df_change[\"label\"].str[0] != df_change[\"label\"].str[1])) | \n",
    "\t\t\t\t\t\t\t((df_change[\"significant\"] == \"-\") & (df_change[\"label\"].str[0] == df_change[\"label\"].str[1]))] \"\"\"\n",
    "df_change_filter = df_change[((df_change[\"significant\"] == \"*\")) | \n",
    "\t\t\t\t\t\t\t((df_change[\"significant\"] == \"-\") & (df_change[\"label\"].str[0] == df_change[\"label\"].str[1]))]\n",
    "df_change_filter\n",
    "df_change_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_change[df_change[\"label\"].str.contains(\"?\", regex=False)]\n",
    "# df_change[df_change[\"label\"].str.contains(\"?\", regex=False) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_change_filter = df_change[df_change[\"p-value\"] < 0.01]\n",
    "df_change_filter_all = df_change[df_change[\"significant\"] == \"*\"]\n",
    "df_change_filter_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Union\n",
    "\n",
    "df_change_filter_u = df_change_filter_all.copy()\n",
    "df_change_filter_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersection\n",
    "\n",
    "df_change_filter_i = df_change_filter_all[df_change_filter_all[\"label\"].str.contains(\"?\", regex=False) == False]\n",
    "df_change_filter_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_change_filter = df_change_filter_u # df_change_filter_u, df_change_filter_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count nodes, edges, metabolities names\n",
    "total_nodes = np.unique(np.sort(df_change_filter[[\"source\", \"target\"]], axis=None))\n",
    "\n",
    "nodes_source = np.unique(df_change_filter[df_change_filter[\"source2\"] != \"Unknown\"][\"source\"].values)\n",
    "nodes_target = np.unique(df_change_filter[df_change_filter[\"target2\"] != \"Unknown\"][\"target\"].values)\n",
    "nodes_name = np.unique(np.concatenate((nodes_source, nodes_target)))\n",
    "\n",
    "len(total_nodes), len(nodes_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nodes with name\n",
    "\n",
    "nodes_source = np.unique(df_change_filter[df_change_filter[\"source2\"] != \"Unknown\"][\"source\"].values)\n",
    "nodes_target = np.unique(df_change_filter[df_change_filter[\"target2\"] != \"Unknown\"][\"target\"].values)\n",
    "unique_nodes = np.unique(np.concatenate((nodes_source, nodes_target)))\n",
    "unique_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_change_filter[df_change_filter[\"label\"].str.contains(\"?\", regex=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "12"
    }
   },
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(df_change_filter, source=\"source\", target=\"target\", edge_attr=[\"label\"], create_using=nx.DiGraph())\n",
    "nodes = sorted(list(G.nodes()))\n",
    "print(nodes)\n",
    "\n",
    "df_nodes_raw = df_join_raw.loc[nodes]\n",
    "df_nodes_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "# node degree\n",
    "\n",
    "\"\"\" degrees = dict(G.degree())\n",
    "\n",
    "sorted_nodes = sorted(degrees, key=lambda x: degrees[x], reverse=True)\n",
    "sorted_nodes[:10] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by nodes\n",
    "view_by = 1 # change [(\"Average Mz\", 0), (\"Metabolite name\", 1)] \n",
    "\n",
    "# nodes_select = sorted([32, 51, 56, 59, 67, 78, 80]) # leaf\n",
    "# nodes_select = [0, 1, 2, 3, 4, 5, 6] # mutant\n",
    "# nodes_select = sorted([2979, 3030, 1205, 48, 1750, 1862]) # cancer\n",
    "# nodes_select = sorted([862, 1209, 1207, 1098, 1033, 1210]) # tea\n",
    "nodes_select = unique_nodes # change\n",
    "\n",
    "df_nodes_raw_filter = df_nodes_raw.loc[nodes_select,:]\n",
    "df_nodes_raw_filter\n",
    "\n",
    "nodes, values = list(df_nodes_raw_filter.index), list(df_nodes_raw_filter.values.tolist())\n",
    "\n",
    "SG = G.subgraph(nodes)\n",
    "print(nodes, SG.nodes())\n",
    "print(SG.edges())\n",
    "\n",
    "# SG = nx.relabel_nodes(SG, id_mz)\n",
    "edge_labels = nx.get_edge_attributes(SG, \"label\")\n",
    "edge_labels\n",
    "\n",
    "canvas = algorithmx.jupyter_canvas()\n",
    "canvas.size((600, 600))\n",
    "canvas.edgelayout(\"symmetric\").edgelength(85)\n",
    "canvas.label(\"title\").add({\"text\": \"{} --> {}\".format(group[0], group[1])})\n",
    "\n",
    "canvas.nodes(nodes).add({\n",
    "\t\"color\": \"orange\",\n",
    "\t\"svgattrs\": {\n",
    "\t\t\"stroke-width\": 2,\n",
    "\t\t\"stroke\": \"gray\"\n",
    "\t}\n",
    "}).data(values).add(\n",
    "\tsize=(16),\n",
    "\tlabels=lambda d: {\n",
    "\t\t0: {\"color\": \"black\", \"text\": d[view_by], \"size\": 14}\n",
    "\t}\n",
    ")\n",
    "\n",
    "# Add directed edges with weight labels\n",
    "canvas.edges(SG.edges).add({\n",
    "\t\"color\": \"gray\",\n",
    "\t\"directed\": True,\n",
    "\t\"thickness\": 2}).data(edge_labels.values()).add(\n",
    "\t\tlabels=lambda label: {\n",
    "\t\t\t1: {\"color\": \"black\", \"text\": label, \"size\": 14},\n",
    "\t\t}\n",
    "\t)\n",
    "canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_change_filter[(df_change_filter[\"source\"] == 1205) & (df_change_filter[\"target\"] == 1862)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes_raw_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BioCyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form\n",
    "\n",
    "dict_groups = {}\n",
    "for group in groups:\n",
    "\tdict_groups[\"-\".join(group)] = group\n",
    "dict_groups\n",
    "\n",
    "form_item_layout = Layout(\n",
    "\tdisplay='flex',\n",
    "\tflex_flow='row',\n",
    "\tjustify_content='space-between'\n",
    ")\n",
    "\n",
    "exp_ = Text(\n",
    "\tvalue=\"\",\n",
    "\tplaceholder='Type Experiment Code',\n",
    "\tdisabled=False   \n",
    ")\n",
    "\n",
    "methods = Dropdown(\n",
    "\toptions=[\"vgae\", \"dgi\"],\n",
    "\tvalue=\"vgae\",\n",
    "\tdisabled=False\n",
    ")\n",
    "data_variations = Dropdown(\n",
    "\toptions=[\"none\", \"str\", \"dyn\"],\n",
    "\tvalue=\"none\",\n",
    "\tdisabled=False\n",
    ")\n",
    "groups_ = Dropdown(\n",
    "\toptions=list(dict_groups.keys()),\n",
    "\tvalue=list(dict_groups.keys())[0],\n",
    "\tdisabled=False\n",
    ")\n",
    "threshold_ratio_ = FloatSlider(\n",
    "\tvalue=0.5,\n",
    "\tmin=-1.0,\n",
    "\tmax=1.0,\n",
    "\tstep=0.01,\n",
    "\tdisabled=False,\n",
    "\tcontinuous_update=False,\n",
    "\torientation='horizontal',\n",
    "\treadout=True,\n",
    ")\n",
    "views_by = Dropdown(\n",
    "\toptions=[(\"Average Mz\", 1), (\"Metabolite name\", 0)],\n",
    "\tvalue=1,\n",
    "\tdisabled=False\n",
    ")\n",
    "\n",
    "form_items = [\n",
    "\tBox([Label(value=\"Experiment code\"), exp_], layout=form_item_layout),\n",
    "\tBox([Label(value=\"Method\"), methods], layout=form_item_layout),\n",
    "\tBox([Label(value=\"Data variation\"), data_variations], layout=form_item_layout),\n",
    "\tBox([Label(value=\"Group\"), groups_], layout=form_item_layout),\n",
    "\tBox([Label(value=\"Threshold ratio\"), threshold_ratio_], layout=form_item_layout),\n",
    "\tBox([Label(value=\"View by\"), views_by], layout=form_item_layout),\n",
    "]\n",
    "\n",
    "form = Box(form_items, layout=Layout(\n",
    "\tdisplay='flex',\n",
    "\tflex_flow='column',\n",
    "\tborder='solid 1px',\n",
    "\talign_items='stretch',\n",
    "\twidth='50%'\n",
    "))\n",
    "form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = exp_.value\n",
    "method = methods.value\n",
    "data_variation = data_variations.value\n",
    "group = dict_groups[groups_.value]\n",
    "threshold_ratio = threshold_ratio_.value\n",
    "view_by = views_by.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biocyc = pd.read_csv(\"experiments/output/{}/biocyc/biocyc_{}_{}_{}.csv\".format(exp, method, \"-\".join(group), data_variation), sep=\"\\t\")\n",
    "df_biocyc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biocyc_filter = df_biocyc[df_biocyc[\"Ratio\"].abs() > threshold_ratio].copy()\n",
    "df_biocyc_filter.sort_values(by=[\"Alignment ID\"], inplace=True)\n",
    "df_biocyc_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=go.Heatmap(\n",
    "\tz=df_biocyc_filter.iloc[:, 3:5].T.values,\n",
    "\ty=group,\n",
    "\tx=list(map(str, df_biocyc_filter.iloc[:, view_by].values)),\n",
    "\thoverongaps=False))\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "\tz=df_biocyc_filter.iloc[:, -1:].T.values,\n",
    "\ty=[\"Ratio\"],\n",
    "\tx=list(map(str, df_biocyc_filter.iloc[:, view_by].values)),\n",
    "\thoverongaps=False))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run details (loss, embeddings plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# print(exp)\n",
    "exp = \"exp2004\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "dimension = params[\"dimension\"]\n",
    "print(\"Dimension:\\t\", dimension)\n",
    "\n",
    "threshold_corr = params[\"threshold_corr\"]\n",
    "print(\"Threshold corr:\\t\", threshold_corr)\n",
    "\n",
    "iterations = params[\"iterations\"]\n",
    "print(\"Iterations:\\t\", iterations)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "seeds = params[\"seeds\"]\n",
    "print(\"Seeds:\\t\\t\", seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# plot loss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "iteration = 1 # change\n",
    "dimensions = [2, 3, 4, 8, 16, 32, 64, 128, 256, 512] # change\n",
    "\n",
    "fig, axs = plt.subplots(3 * 4 * len(methods), len(dimensions), figsize=(60, 160))\n",
    "e = 2004 # change\n",
    "for j, dim in enumerate(dimensions): # change, experiment\n",
    "\texp = \"exp\" + str(e + j)\n",
    "\ti = 0\n",
    "\tfor method in methods[:]: # change\n",
    "\t\tfor group_id in groups_id[:]: # change\n",
    "\t\t\tfor data_variation in data_variations: # change\n",
    "\t\t\t\tprint(method, group_id, data_variation)\n",
    "\n",
    "\t\t\t\tif data_variation == \"none\":\n",
    "\t\t\t\t\tfor subgroup_id in subgroups_id[group_id]:\n",
    "\t\t\t\t\t\t# print(exp, method, group_id, subgroup_id, iteration)\n",
    "\t\t\t\t\t\tname_file = \"experiments/run_details/{}_{}_{}_{}_1\".format(exp, method, group_id, subgroup_id)\n",
    "\t\t\t\t\t\t# embeddings = np.load(\"{}_embeddings.npy\".format(name_file))\n",
    "\t\t\t\t\t\tlosses = np.load(\"{}_loss.npy\".format(name_file))\n",
    "\n",
    "\t\t\t\t\t\tx = range(1, len(losses))\n",
    "\t\t\t\t\t\ty = losses[:-1]\n",
    "\t\t\t\t\t\taxs[i, j].plot(x, y, \"o-\")\n",
    "\t\t\t\t\t\taxs[i, j].axvline(x=losses[-1], color=\"red\")\n",
    "\t\t\t\t\t\taxs[i, j].grid()\n",
    "\t\t\t\t\t\taxs[i, j].set_title(\"{}-{}-{}{}-dim: {}\".format(method, group_id, data_variation, subgroup_id, dim))\n",
    "\t\t\t\t\t\t# plt.show()\n",
    "\t\t\t\t\t\t# print(y)\n",
    "\t\t\t\t\t\t# print(i, j)\n",
    "\t\t\t\t\t\ti += 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tname_file = \"experiments/run_details/{}_{}_{}_{}_1\".format(exp, method, group_id, data_variation)\n",
    "\t\t\t\t\t# embeddings = np.load(\"{}_embeddings.npy\".format(name_file))\n",
    "\t\t\t\t\tlosses = np.load(\"{}_loss.npy\".format(name_file))\n",
    "\n",
    "\t\t\t\t\tx = range(1, len(losses))\n",
    "\t\t\t\t\ty = losses[:-1]\n",
    "\t\t\t\t\taxs[i, j].plot(x, y, \"o-\")\n",
    "\t\t\t\t\taxs[i, j].axvline(x=losses[-1], color=\"red\")\n",
    "\t\t\t\t\taxs[i, j].grid()\n",
    "\t\t\t\t\taxs[i, j].set_title(\"{}-{}-{}-dim: {}\".format(method, group_id, data_variation, dim))\n",
    "\t\t\t\t\t# plt.show()\n",
    "\t\t\t\t\t# print(y)\n",
    "\t\t\t\t\t# print(i, j)\n",
    "\t\t\t\t\ti += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot node-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1 # change\n",
    "dimensions = [2, 3, 4, 8, 16, 32, 64, 128, 256, 512] # change\n",
    "\n",
    "fig, axs = plt.subplots(3 * 3 * len(methods), len(dimensions), figsize=(60, 160), subplot_kw=dict(projection=\"3d\"))\n",
    "e = 2010 # change\n",
    "for j, dim in enumerate(dimensions): # change, experiment\n",
    "\texp = \"exp\" + str(e + j)\n",
    "\ti = 0\n",
    "\tfor method in methods[:]: # change\n",
    "\t\tfor group_id in groups_id[:]: # change\n",
    "\t\t\tfor data_variation in data_variations: # change\n",
    "\t\t\t\tdf_node_embeddings_concat = pd.DataFrame()\n",
    "\t\t\t\tif data_variation == \"none\":\n",
    "\t\t\t\t\tk = 0\n",
    "\t\t\t\t\tfor subgroup_id in subgroups_id[group_id]:\n",
    "\t\t\t\t\t\tprint(exp, method, group_id, subgroup_id, iteration)\n",
    "\t\t\t\t\t\tdf_node_embeddings = pd.read_csv(\"experiments/output/{}/node_embeddings/node-embeddings_{}_{}_{}_{}.csv\".format(exp, method, group_id, subgroup_id, iteration), index_col=0)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tdf_node_embeddings[\"subgroup\"] = [k] * len(df_node_embeddings)\n",
    "\t\t\t\t\t\tdf_node_embeddings_concat = pd.concat([df_node_embeddings_concat, df_node_embeddings])\n",
    "\t\t\t\t\t\tk += 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(exp, method, group_id, data_variation, iteration)\n",
    "\t\t\t\t\tdf_nodes = pd.read_csv(\"experiments/output/{}/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(exp, group_id, data_variation), index_col=0, usecols=[0, 1])\n",
    "\t\t\t\t\tdf_nodes[\"subgroup\"] = df_nodes[\"id\"].apply(lambda x: ord(x[0]) - 65)\n",
    "\n",
    "\t\t\t\t\tdf_node_embeddings = pd.read_csv(\"experiments/output/{}/node_embeddings/node-embeddings_{}_{}_{}_{}.csv\".format(exp, method, group_id, data_variation, iteration), index_col=0)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tdf_node_embeddings[\"subgroup\"] = df_nodes[\"subgroup\"]\n",
    "\t\t\t\t\tdf_node_embeddings_concat = pd.concat([df_node_embeddings_concat, df_node_embeddings])\n",
    "    \n",
    "\t\t\t\t# plot\n",
    "\t\t\t\tdf_embeddings, labels = df_node_embeddings_concat.iloc[:, :-1], df_node_embeddings_concat.iloc[:, -1],\n",
    "\t\t\t\tif df_embeddings.shape[1] > 3:\n",
    "\t\t\t\t\tdf_embeddings_red = PCA(n_components=3).fit_transform(df_embeddings)\n",
    "\t\t\t\t\t# df_embeddings_red = TSNE(n_components=3).fit_transform(df_embeddings)\n",
    "\t\t\t\t\t# df_embeddings_red = umap.UMAP().fit_transform(df_embeddings)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdf_embeddings_red = df_embeddings.values\n",
    "\t\t\t\t\n",
    "\t\t\t\tdf_embeddings = pd.DataFrame(df_embeddings_red)\n",
    "\t\t\t\tdf_embeddings[\"labels\"] = labels.values\n",
    "\t\t\t\t\n",
    "\t\t\t\tunique_labels = np.unique(labels)\n",
    "\n",
    "\t\t\t\tfor k, label in enumerate(unique_labels):\n",
    "\t\t\t\t\tdf_embeddings_filter = df_embeddings[df_embeddings[\"labels\"] == label]\n",
    "\n",
    "\t\t\t\t\tx = df_embeddings_filter.iloc[:, 0]\n",
    "\t\t\t\t\ty = df_embeddings_filter.iloc[:, 1]\n",
    "\t\t\t\t\tz = df_embeddings_filter.iloc[:, 2]\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tcolor = matplotlib.colors.ListedColormap(plt.cm.Dark2.colors[k: k + 1]).colors[0]\n",
    "\t\t\t\t\t# points = ax.scatter(x, y, z, s=100, c=labels, alpha=0.5, cmap=new_cmap , marker=\".\") # , edgecolors=\"black\", linewidth=0.5)\n",
    "\t\t\t\t\taxs[i, j].scatter(x, y, z, s=100, alpha=0.5, color=color, marker=\".\", label=\"Br{}\".format(label + 1))\n",
    "\t\t\t\t\taxs[i, j].set_title(\"{}-{}-{}-dim: {}\".format(method, group_id, data_variation, dim))\n",
    "\t\t\t\ti += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot edge-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1 # change\n",
    "dimensions = [2, 3, 4, 8, 16, 32, 64, 128, 256, 512] # change\n",
    "plot_option = \"edge\" # change edge, outlier\n",
    "fig, axs = plt.subplots(3 * 3 * len(methods), len(dimensions), figsize=(60, 160), subplot_kw=dict(projection=\"3d\"))\n",
    "e = 2010 # change\n",
    "\n",
    "for j, dim in enumerate(dimensions): # change, experiment\n",
    "\texp = \"exp\" + str(e + j)\n",
    "\ti = 0\n",
    "\tfor method in methods[:]: # change\n",
    "\t\tfor group_id in groups_id[:]: # change\n",
    "\t\t\tfor data_variation in data_variations: # change\n",
    "\t\t\t\tprint(exp, method, group_id, data_variation, iteration)\n",
    "\t\t\t\tdf_edge_embeddings_concat = pd.read_csv(\"experiments/output/{}/edge_embeddings/edge-embeddings_concat_outlier_{}_{}_{}_{}.csv\".format(exp, method, group_id, data_variation, iteration))\n",
    "\t\t\t\t\n",
    "\t\t\t\t# plot without synthetic edges\n",
    "\t\t\t\tdf_edge_embeddings_concat = df_edge_embeddings_concat[df_edge_embeddings_concat[\"subgroup\"] != -1]\n",
    "    \n",
    "\t\t\t\t# plot\n",
    "\t\t\t\tif plot_option == \"edge\":\n",
    "\t\t\t\t\tdf_embeddings, labels = df_edge_embeddings_concat.iloc[:, 2:-2], df_edge_embeddings_concat.iloc[:, -2]\n",
    "\t\t\t\telif plot_option == \"outlier\":\n",
    "\t\t\t\t\tdf_embeddings, labels = df_edge_embeddings_concat.iloc[:, 2:-2], df_edge_embeddings_concat.iloc[:, -1]\n",
    "\n",
    "\t\t\t\tif df_embeddings.shape[1] > 3:\n",
    "\t\t\t\t\tdf_embeddings_red = PCA(n_components=3).fit_transform(df_embeddings)\n",
    "\t\t\t\t\t# df_embeddings_red = TSNE(n_components=3).fit_transform(df_embeddings)\n",
    "\t\t\t\t\t# df_embeddings_red = umap.UMAP().fit_transform(df_embeddings)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tdf_embeddings_red = df_embeddings.values\n",
    "\t\t\t\t\n",
    "\t\t\t\tdf_embeddings = pd.DataFrame(df_embeddings_red)\n",
    "\t\t\t\tdf_embeddings[\"labels\"] = labels.values\n",
    "\t\t\t\tnum_cols = len(df_embeddings.columns)\n",
    "\t\t\t\tunique_labels = np.unique(labels)\n",
    "\t\t\t\t# print(unique_labels)\n",
    "\t\t\t\tfor k, label in enumerate(unique_labels):\n",
    "\t\t\t\t\tdf_embeddings_filter = df_embeddings[df_embeddings[\"labels\"] == label]\n",
    "\n",
    "\t\t\t\t\tx = df_embeddings_filter.iloc[:, 0]\n",
    "\t\t\t\t\ty = df_embeddings_filter.iloc[:, 1]\n",
    "\t\t\t\t\tif num_cols == 3:\n",
    "\t\t\t\t\t\tz = [0] * len(df_embeddings_filter)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tz = df_embeddings_filter.iloc[:, 2]\n",
    "\n",
    "\t\t\t\t\tif plot_option == \"edge\":\n",
    "\t\t\t\t\t\tcolor = matplotlib.colors.ListedColormap(plt.cm.Dark2.colors[k: k + 1]).colors[0]\n",
    "\t\t\t\t\t\taxs[i, j].scatter(x, y, z, s=100, alpha=0.5, color=color, marker=\".\", label=\"Br{}\".format(label + 1))\n",
    "\t\t\t\t\t\taxs[i, j].set_title(\"{}-{}-{}-dim: {}\".format(method, group_id, data_variation, dim))\n",
    "\t\t\t\t\telif plot_option == \"outlier\":\n",
    "\t\t\t\t\t\tcolors = plt.get_cmap(\"coolwarm\")(np.linspace(0, 1, len(unique_labels)))\n",
    "\t\t\t\t\t\taxs[i, j].scatter(x, y, z, s=100, alpha=0.5, c=[colors[label]], marker=\".\", label=[\"inliers\", \"outliers\"][label]) #, edgecolors=\"black\", linewidth=0.5)\n",
    "\t\t\t\t\t\taxs[i, j].set_title(\"{}-{}-{}-dim: {}\".format(method, group_id, data_variation, dim))\n",
    "\t\t\t\ti += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot interactive embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib widget\n",
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython import display\n",
    "from IPython.display import HTML\n",
    "from matplotlib import animation\n",
    "\n",
    "df_nodes = pd.read_csv(\"experiments/output/{}/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(exp, group_id, data_variation), index_col=0, usecols=[0, 1])\n",
    "df_nodes[\"subgroup\"] = df_nodes[\"id\"].apply(lambda x: ord(x[0]) - 65)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(projection=\"3d\")\n",
    "\"\"\" plt.axis('off')\n",
    "plt.tick_params(left=False,\n",
    "\t\t\t\tbottom=False,\n",
    "\t\t\t\tlabelleft=False,\n",
    "\t\t\t\tlabelbottom=False) \"\"\"\n",
    "def animate(i):\n",
    "\tdf_node_embeddings = pd.DataFrame(embeddings[i])\n",
    "\tdf_node_embeddings[\"subgroup\"] = df_nodes[\"subgroup\"]\n",
    "\t\n",
    "\tx = df_node_embeddings.iloc[:, 0]\n",
    "\ty = df_node_embeddings.iloc[:, 1]\n",
    "\tz = df_node_embeddings.iloc[:, 2]\n",
    "\tlabels = df_node_embeddings.iloc[:, 3]\n",
    "\t\n",
    "\tax.clear()\n",
    "\tax.scatter(x, y, z, c=labels, s=100)\n",
    "\tplt.title(f'Epoch: {i + 1} | Loss: {losses[i]:.2f}', fontsize=12, pad=10)\n",
    "\n",
    "ani = matplotlib.animation.FuncAnimation(fig, animate, frames=len(embeddings), interval=1000)\n",
    "html = HTML(ani.to_jshtml())\n",
    "display.display(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1 # change\n",
    "print(exp, method, group_id, data_variation, iteration)\n",
    "df_edge_embeddings_concat = pd.read_csv(\"experiments/output/{}/edge_embeddings/edge-embeddings_concat_outlier_{}_{}_{}_{}.csv\".format(exp, method, group_id, data_variation, iteration))\n",
    "\n",
    "plot_embedding_3d(df_edge_embeddings_concat.iloc[:, 2:-2], df_edge_embeddings_concat.iloc[:, -1], reduction=\"pca\", embedding=\"edge\", title=\"{}-{}\".format(method, group_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_embeddings_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "\tx=df_edge_embeddings_concat.iloc[:, 2],\n",
    "\ty=df_edge_embeddings_concat.iloc[:, 3],\n",
    "\tz=df_edge_embeddings_concat.iloc[:, 4],\n",
    "\tmode=\"markers\",\n",
    "\tmarker=dict(\n",
    "\t\tsize=6,\n",
    "\t\tcolor=df_edge_embeddings_concat.iloc[:, 6], # set color to an array/list of desired values\n",
    "\t\tcolorscale=\"Portland\",   # choose a colorscale\n",
    "\t\topacity=0.8\n",
    "\t)\n",
    ")])\n",
    "\n",
    "# tight layout\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison on synthetic raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff sigmas\n",
    "\n",
    "sigma_p1 = np.load(\"synthetic_dataset/sigma1_v5.npy\") # load\n",
    "sigma_p2 = np.load(\"synthetic_dataset/sigma2_v5.npy\") # load\n",
    "diff = sigma_p1 - sigma_p2\n",
    "\n",
    "np.fill_diagonal(sigma_p1, 0)\n",
    "np.fill_diagonal(sigma_p2, 0)\n",
    "\n",
    "plt.imshow(sigma_p1, cmap=\"coolwarm\", interpolation=\"none\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(sigma_p2, cmap=\"coolwarm\", interpolation=\"none\")\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(diff, cmap=\"coolwarm\", interpolation=\"none\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_p1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw, col = sigma_p1.shape\n",
    "for i in range(raw):\n",
    "\tfor j in range(i, col):\n",
    "\t\tif abs(sigma_p1[i][j]) < 0.5:\n",
    "\t\t\tsigma_p1[i][j] = 0\n",
    "\t\t\tsigma_p1[j][i] = 0\n",
    "\t\t\t\n",
    "plt.imshow(sigma_p1, cmap=\"coolwarm\", interpolation=\"none\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw, col = sigma_p2.shape\n",
    "for i in range(raw):\n",
    "\tfor j in range(i, col):\n",
    "\t\tif abs(sigma_p2[i][j]) < 0.5:\n",
    "\t\t\tsigma_p2[i][j] = 0\n",
    "\t\t\tsigma_p2[j][i] = 0\n",
    "\t\t\t\n",
    "plt.imshow(sigma_p2, cmap=\"coolwarm\", interpolation=\"none\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get significant edges \n",
    "list_edges_sigma = []\n",
    "row, col = diff.shape\n",
    "th = 0.5\n",
    "\n",
    "for i in range(row):\n",
    "\tfor j in range(i, col):\n",
    "\t\tif True: # (sigma_p1[i, j] * sigma_p2[i, j] < 0): # or (abs(sigma_p1[i, j] - sigma_p2[i, j]) >= th):\n",
    "\t\t\tlist_edges_sigma.append([i, j,]) #, \"*\"])\n",
    "\n",
    "print(len(list_edges_sigma))\n",
    "list_edges_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = np.array(list_edges_sigma)\n",
    "unique_nodes = np.unique(aux.flatten()).tolist()\n",
    "unique_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"exp571\"\n",
    "\n",
    "df_join_raw = pd.read_csv(\"experiments/input/{}_raw.csv\".format(exp), index_col=0)        \n",
    "# df_join_raw.columns = [\"mz\", \"name\"]\n",
    "df_join_raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = df_join_raw.iloc[unique_nodes,:]\n",
    "print(s1.shape)\n",
    "s1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "\n",
    "# save\n",
    "s1.to_csv(\"experiments/raw_data/synthetic_greedy_all_format.csv\", index=True, sep=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(exp)\n",
    "exp = \"exp601\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "# print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "control = params[\"control\"]\n",
    "print(\"Control:\\t\", control)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_raw = pd.read_csv(\"experiments/input/{}_raw.csv\".format(exp), index_col=0, usecols=[0, 1, 2])        \n",
    "# df_join_raw.columns = [\"mz\", \"name\"]\n",
    "df_join_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_edges_(edges):\n",
    "\tedges_ = []\n",
    "\tfor k in range(len(edges)):\n",
    "\t\tif edges[k][0] > edges[k][1]:\n",
    "\t\t\tedges_.append((edges[k][1], edges[k][0]))\n",
    "\t\telse:\n",
    "\t\t\tedges_.append((edges[k][0], edges[k][1]))\n",
    "\treturn edges_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for method in methods:\n",
    "\tfor group in groups:\n",
    "\t\tfor data_variation in data_variations:\n",
    "\t\t\t\"\"\" print(method)\n",
    "\t\t\tprint(data_variation)\n",
    "\t\t\tprint(group) \"\"\"\n",
    "\t\t\t\n",
    "\t\t\tdf_change = pd.read_csv(\"experiments/output/{}/changes/changes_edges_log2_{}_{}_{}_{}.csv\".format(exp, method, group[0], group[1], data_variation))\n",
    "\t\t\t# G = nx.from_pandas_edgelist(df_change_filter, edge_attr=[\"label\"], create_using=nx.DiGraph())\n",
    "\t\t\tdf_change\n",
    "\t\t\t\n",
    "\t\t\tdf_change_filter = df_change[df_change[\"significant\"] == \"*\"]\n",
    "\t\t\tdf_change_filter\n",
    "\t\t\t\n",
    "\t\t\tlist_edges_gnn = df_change_filter.iloc[:, [0, 1]].values.tolist()\n",
    "\t\t\t# print(len(list_edges_gnn))\n",
    "\t\t\tlist_edges_gnn\n",
    "\t\t\t\n",
    "\t\t\t# print(len(list_edges_sigma))\n",
    "\t\t\tlist_edges_sigma\n",
    "\t\t\t\n",
    "\t\t\ts1 = set(sort_edges_(list_edges_sigma))\n",
    "\t\t\ts2 = set(sort_edges_(list_edges_gnn))\n",
    "\t\t\t\n",
    "\t\t\tintersection = s1 & s2\n",
    "\t\t\tprint(len(list_edges_sigma), len(list_edges_gnn), len(intersection))\n",
    "\t\t\tratio = len(intersection) / len(list_edges_sigma)\n",
    "\t\t\tratio\n",
    "\t\t\t\n",
    "\t\t\tdata.append([method, group, data_variation, ratio])\n",
    "df = pd.DataFrame(data, columns=[\"Method\", \"Group\", \"Data var.\", \"Ratio\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(exp)\n",
    "exp = \"exp800\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "# print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "control = params[\"control\"]\n",
    "print(\"Control:\\t\", control)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_change_greedy = pd.read_csv(\"experiments/output/{}/changes/changes_edges_log2_{}_{}_{}_{}.csv\".format(exp, \"greedy\", \"AA\", \"BB\", \"none\"))\n",
    "df_change_greedy = df_change_greedy[df_change_greedy[\"significant\"] == \"*\"]\n",
    "df_change_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = nx.from_pandas_edgelist(df_change_greedy, \"source\", \"target\", edge_attr=\"weight1\")\n",
    "\n",
    "edges_greedy = sort_edges(G0.edges())\n",
    "edges_greedy[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for method in methods:\n",
    "\tfor group in groups:\n",
    "\t\tfor data_variation in data_variations:\n",
    "\t\t\t\"\"\" print(method)\n",
    "\t\t\tprint(data_variation)\n",
    "\t\t\tprint(group) \"\"\"\n",
    "\t\t\t\n",
    "\t\t\tdf_change = pd.read_csv(\"experiments/output/{}/changes/changes_edges_log2_{}_{}_{}_{}.csv\".format(exp, method, group[0], group[1], data_variation))\n",
    "\t\t\t# G = nx.from_pandas_edgelist(df_change_filter, edge_attr=[\"label\"], create_using=nx.DiGraph())\n",
    "\t\t\t\n",
    "\t\t\tdf_change_filter = df_change[df_change[\"significant\"] == \"*\"]\n",
    "\t\t\tdf_change_filter\n",
    "\t\t\t\n",
    "\t\t\tG1 = nx.from_pandas_edgelist(df_change_filter, \"source\", \"target\", edge_attr=\"weight1\")\n",
    "\t\t\t\n",
    "\t\t\tedges = sort_edges(G1.edges())\n",
    "\n",
    "\t\t\ts1 = set(sort_edges(G0.edges()))\n",
    "\t\t\ts2 = set(sort_edges(G1.edges()))\n",
    "\t\t\t\n",
    "\t\t\tintersection = s1 & s2\n",
    "\t\t\t\"\"\" print(len(list_edges_sigma), len(list_edges_gnn), len(intersection))\n",
    "\t\t\tratio = len(intersection) / len(list_edges_sigma)\n",
    "\t\t\tratio \"\"\"\n",
    "\t\t\t\n",
    "\t\t\tdata.append([method, group, data_variation, len(edges_greedy), len(edges), len(intersection)])\n",
    "df = pd.DataFrame(data, columns=[\"Method\", \"Group\", \"Data var.\", \"* greedy\", \"* GNN\", \"common\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "\n",
    "for i in range(len(df)):\n",
    "\t# print(df.iloc[i,:])\n",
    "\ta = df.iloc[i,:][\"* greedy\"]\n",
    "\tb = df.iloc[i,:][\"* GNN\"]\n",
    "\tc = df.iloc[i,:][\"common\"]\n",
    "\t\n",
    "\tmethod = df.iloc[i,:][\"Method\"] + \"-\" + df.iloc[i,:][\"Data var.\"]\n",
    "\tprint(method)\n",
    "\t\n",
    "\tvenn2((a - c, b - c, c), set_labels=(\"Greedy\", method))\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "\n",
    "exp = \"exp571\"\n",
    "\n",
    "# details\n",
    "list_graph_greedy = []\n",
    "list_graph_gnn = []\n",
    "\n",
    "for group in groups_id:\n",
    "\tdf_common_edges = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}.csv\".format(exp, \"greedy\", group, \"none\"))\n",
    "\tG = nx.from_pandas_edgelist(df_common_edges, edge_attr=[\"weight\"])\n",
    "\tlist_graph_greedy.append(G)\n",
    "\n",
    "for k, group in enumerate(groups_id):\n",
    "\tfor method in methods:\n",
    "\t\tfor data_variation in data_variations:\n",
    "\t\t\tdf_edges_filter_weight_filter = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}.csv\".format(exp, method, group, data_variation))\n",
    "\t\t\tG = nx.from_pandas_edgelist(df_edges_filter_weight_filter, \"source\", \"target\", edge_attr=\"weight\")\n",
    "\t\t\t\n",
    "\t\t\tprint(method, group, data_variation)\n",
    "\t\t\tnodes1 = set(list(list_graph_greedy[k].nodes()))\n",
    "\t\t\tnodes2 = set(list(G.nodes()))\n",
    "\t\t\t\n",
    "\t\t\tedges1 = set(sort_edges(list_graph_greedy[k].edges()))\n",
    "\t\t\tedges2 = set(sort_edges(G.edges()))\n",
    "\t\t\t\n",
    "\t\t\tfig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\t\t\t# Plot the Venn diagram for the first column\n",
    "\t\t\tvenn2(subsets=[nodes1, nodes2],\n",
    "\t\t\t\tset_labels=(\"Greedy\", method),\n",
    "\t\t\t\tax=axes[0])\n",
    "\t\t\taxes[0].set_title(\"Nodes\")\n",
    "\n",
    "\t\t\tvenn2(subsets=[edges1, edges2],\n",
    "\t\t\t\tset_labels=(\"Greedy\", method),\n",
    "\t\t\t\tax=axes[1])\n",
    "\t\t\taxes[1].set_title(\"Edges\")\n",
    "\n",
    "\t\t\tplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify synthetic raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1001\n",
    "for br in [2, 3, 4, 5]:\n",
    "\tfor ar in [2, 3, 4, 5]:\n",
    "\t\tdf = pd.read_csv(\"experiments/raw_data/synthetic_br{}_ar{}_v7_format.csv\".format(br, ar), sep=\"|\")\n",
    "\t\tprint(k, br, ar)\n",
    "\t\tprint(df.dtypes)\n",
    "\t\tprint(df.describe())\n",
    "\t\tprint()\n",
    "\t\tk += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(1250126, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_data = pd.read_csv(\"experiments/output/{}/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(\"exp1009\", \"AA\", subgroup)).iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison (num edges) difference number of Br and Ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sysnthetic dataset\n",
    "\n",
    "# print(exp)\n",
    "exp = \"exp1233\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "# print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "control = params[\"control\"]\n",
    "print(\"Control:\\t\", control)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By number of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by number of edges\n",
    "\n",
    "list_br = [2, 3, 4, 5]\n",
    "list_ar = [2, 3, 4, 5]\n",
    "e = 1233 # change\n",
    "\n",
    "df_details = pd.DataFrame()\n",
    "\n",
    "for br in list_br:\n",
    "\tfor ar in list_ar:\n",
    "\t\texp = \"exp\" + str(e)\n",
    "\t\tprint(exp)\n",
    "\t\t\n",
    "\t\tlist_details = []\n",
    "\t\tlist_graph_greedy = []\n",
    "  \n",
    "\t\tfor group in groups_id:\n",
    "\t\t\tdf_common_edges = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}.csv\".format(exp, \"greedy\", group, \"none\"))\n",
    "\t\t\tG = nx.from_pandas_edgelist(df_common_edges, edge_attr=[\"weight\"])\n",
    "\t\t\t# edges_greedy = sort_edges(G0.edges())\n",
    "\t\t\tlist_graph_greedy.append(G)\n",
    "\t\t\t\n",
    "\t\tfor method in methods:\n",
    "\t\t\tfor k, group in enumerate(groups_id):\n",
    "\t\t\t\tfor data_variation in data_variations:\n",
    "\t\t\t\t\tdf_edges_filter_weight_filter = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}.csv\".format(exp, method, group, data_variation))\n",
    "\n",
    "\t\t\t\t\tG0 = list_graph_greedy[k]\n",
    "\t\t\t\t\tG1 = nx.from_pandas_edgelist(df_edges_filter_weight_filter, \"source\", \"target\", edge_attr=\"weight\")\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\ts1 = set(sort_edges(G0.edges()))\n",
    "\t\t\t\t\ts2 = set(sort_edges(G1.edges()))\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tintersection = s1 & s2\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tlist_details.append([method, group, data_variation, br, ar, G0.number_of_edges(), G1.number_of_edges(), len(intersection)])\n",
    "\t\te += 1\n",
    "\t\tdf_aux = pd.DataFrame(list_details, columns=[\"Method\", \"Group\", \"Data var.\", \"Br\", \"Ar\", \"Num. edges (Greedy)\", \"Num. edges (GNN)\", \"Num. common edges\"])\n",
    "\t\tdf_aux[\"common (%)\"] = np.round((df_aux[\"Num. edges (GNN)\"] / df_aux[\"Num. edges (Greedy)\"]) * 100, 0)\n",
    "\t\t# print(df_aux)\n",
    "\n",
    "\t\tdf_details = pd.concat([df_details, df_aux], ignore_index=True)\n",
    "\t\tdf_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details.to_csv(\"temp/z_comparison_br_ar_num_edges_random.csv\") # change\n",
    "df_details\n",
    "\n",
    "df_details = pd.read_csv(\"temp/z_comparison_br_ar_num_edges_random.csv\", index_col=0)\n",
    "df_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Plot\n",
    "\n",
    "df_details1 = pd.read_csv(\"temp/z_comparison_br_ar_num_edges.csv\", index_col=0)\n",
    "df_details1\n",
    "\n",
    "df_details2 = pd.read_csv(\"temp/z_comparison_br_ar_num_edges_laplacian.csv\", index_col=0)\n",
    "df_details2\n",
    "\n",
    "df_details3 = pd.read_csv(\"temp/z_comparison_br_ar_num_edges_random.csv\", index_col=0)\n",
    "df_details3[\"Method\"] = ([\"DGI\"] * 6 + [\"ARGVA\"] * 6 + [\"LVGAE\"] * 6 + [\"VGAE\"] * 6) * 16\n",
    "df_details3\n",
    "\n",
    "columns = df_details3[\"Method\"] + \"-Br(\" + df_details3[\"Br\"].astype(str) + \")-Ar(\" + df_details3[\"Ar\"].astype(str) + \")\"\n",
    "print(columns)\n",
    "\n",
    "columns_ = [columns[0]]\n",
    "range_ = [0]\n",
    "for k in range(6, len(columns.values), 6):\n",
    "  # columns_.append(columns.values[k - 1])\n",
    "  columns_.append(columns.values[k])\n",
    "\n",
    "  # range_.append(k - 1)\n",
    "  range_.append(k)\n",
    "columns_.append(columns.values[-1])\n",
    "range_.append(len(columns.values) - 1)\n",
    "\n",
    "x = list(range(len(df_details3)))\n",
    "\n",
    "plt.subplots(figsize=(16, 6))\n",
    "y = df_details1[\"Num. common edges\"].values\n",
    "plt.plot(x, y, label=\"GNN\", linestyle=\"solid\", c=\"tab:blue\")\n",
    "# y = df_details1[\"Num. edges (Greedy)\"].values\n",
    "# plt.plot(x, y, label=\"Base-greedy\", linestyle=\"dotted\", c=\"tab:red\")\n",
    "\n",
    "y = df_details2[\"Num. common edges\"].values\n",
    "plt.plot(x, y, label=\"GNN + Laplacian\", linestyle=\"solid\", c=\"tab:orange\")\n",
    "# y = df_details2[\"Num. edges (Greedy)\"].values\n",
    "# plt.plot(x, y, label=\"Laplacian-greedy\", linestyle=\"dotted\", c=\"tab:orange\")\n",
    "\n",
    "y = df_details3[\"Num. common edges\"].values\n",
    "plt.plot(x, y, label=\"GNN + RandomWalk\", linestyle=\"solid\", c=\"tab:green\")\n",
    "y = df_details3[\"Num. edges (Greedy)\"].values\n",
    "plt.plot(x, y, label=\"Greedy\", linestyle=\"dotted\", c=\"tab:red\")\n",
    "\n",
    "plt.xticks(range_, labels=columns_, rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.ylabel(\"Num. edges\")\n",
    "plt.legend(loc=\"best\", frameon=False)\n",
    "plt.grid(axis=\"y\")\n",
    "# plt.grid()\n",
    "plt.savefig(\"experiments/plots/comparison_Br_Ar_positional_enconding.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By number of significant edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by number of edges\n",
    "list_graph_greedy = []\n",
    "\n",
    "list_br = [2, 3, 4, 5]\n",
    "list_ar = [2, 3, 4, 5]\n",
    "e = 1051\n",
    "\n",
    "df_details = pd.DataFrame()\n",
    "for br in list_br:\n",
    "\tfor ar in list_ar:\n",
    "\t\texp = \"exp\" + str(e)\n",
    "\t\tprint(exp)\n",
    "\t\t\n",
    "\t\tdf_change_greedy = pd.read_csv(\"experiments/output/{}/changes/changes_edges_log22_{}_{}_{}_{}.csv\".format(exp, \"greedy\", \"AA\", \"BB\", \"none\"))\n",
    "\t\tdf_change_greedy = df_change_greedy[df_change_greedy[\"significant\"] == \"*\"]\n",
    "\t\tdf_change_greedy\n",
    "\t\tG0 = nx.from_pandas_edgelist(df_change_greedy, \"source\", \"target\", edge_attr=\"weight1\")\n",
    "\t\t\n",
    "\t\tlist_details = []\n",
    "\n",
    "\t\tfor method in methods:\n",
    "\t\t\tfor k, group in enumerate(groups):\n",
    "\t\t\t\tfor data_variation in data_variations:\n",
    "\t\t\t\t\ttry:\n",
    "\t\t\t\t\t\tdf_change = pd.read_csv(\"experiments/output/{}/changes/changes_edges_log22_{}_{}_{}_{}.csv\".format(exp, method, group[0], group[1], data_variation))\n",
    "\t\t\t\t\t\t# G = nx.from_pandas_edgelist(df_change_filter, edge_attr=[\"label\"], create_using=nx.DiGraph())\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\tdf_change_filter = df_change[df_change[\"significant\"] == \"*\"]\n",
    "\t\t\t\t\t\tdf_change_filter\n",
    "\t\t\t\t\t\tG1 = nx.from_pandas_edgelist(df_change_filter, \"source\", \"target\", edge_attr=\"weight1\")\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\ts1 = set(sort_edges(G0.edges()))\n",
    "\t\t\t\t\t\ts2 = set(sort_edges(G1.edges()))\n",
    "\n",
    "\t\t\t\t\t\tintersection = s1 & s2\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tlist_details.append([method, group, data_variation, br, ar, G0.number_of_edges(), G1.number_of_edges(), len(intersection)])\n",
    "\t\t\t\t\texcept:\n",
    "\t\t\t\t\t\tlist_details.append([method, group, data_variation, br, ar, G0.number_of_edges(), 0, 0])\n",
    "\t\te += 1\n",
    "\t\tdf_aux = pd.DataFrame(list_details, columns=[\"Method\", \"Group\", \"Data var.\", \"Br\", \"Ar\", \"Num. edges (Greedy)\", \"Num. edges (GNN)\", \"Num. common edges\"])\n",
    "\t\tdf_aux[\"common (%)\"] = np.round((df_aux[\"Num. edges (GNN)\"] / df_aux[\"Num. edges (Greedy)\"]) * 100, 0)\n",
    "\t\t# print(df_aux)\n",
    "\n",
    "\t\tdf_details = pd.concat([df_details, df_aux], ignore_index=True)\n",
    "\t\tdf_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details.to_csv(\"z_comparison_br_ar_num_edges_significant.csv\")\n",
    "df_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap (common edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"leaf\" # change\n",
    "\n",
    "list_df = []\n",
    "\n",
    "df_edges_count_avg1 = pd.read_csv(\"experiments/run_details/edges_avg_{}.csv\".format(dataset), index_col=0)\n",
    "list_df.append(df_edges_count_avg1)\n",
    "\n",
    "df_edges_count_avg2 = pd.read_csv(\"experiments/run_details/edges_avg_{}_laplacian.csv\".format(dataset), index_col=0)\n",
    "list_df.append(df_edges_count_avg2)\n",
    "\n",
    "df_edges_count_avg3 = pd.read_csv(\"experiments/run_details/edges_avg_{}_random.csv\".format(dataset), index_col=0)\n",
    "list_df.append(df_edges_count_avg3)\n",
    "\n",
    "df_edges_count_avg3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutant\n",
    "\n",
    "a = list_df[0].iloc[0::3, :].round(2).values # pck1\n",
    "b = list_df[0].iloc[1::3, :].round(2).values # zwf1\n",
    "c = list_df[0].iloc[2::3, :].round(2).values # WT\n",
    "\n",
    "for k in range(1, len(list_df)):\n",
    "  a_ = list_df[k].iloc[0::3, :].round(2).values # pck1\n",
    "  b_ = list_df[k].iloc[1::3, :].round(2).values # zwf1\n",
    "  c_ = list_df[k].iloc[2::3, :].round(2).values # WT\n",
    "  \n",
    "  a = np.concatenate((a, a_), axis=1)\n",
    "  b = np.concatenate((b, b_), axis=1)\n",
    "  c = np.concatenate((c, c_), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaf, synthetic\n",
    "\n",
    "a = list_df[0].iloc[0::2, :].round(2).values # new, phetotype1\n",
    "b = list_df[0].iloc[1::2, :].round(2).values # old phenotype2\n",
    "\n",
    "for k in range(1, len(list_df)):\n",
    "  a_ = list_df[k].iloc[0::2, :].round(2).values # \n",
    "  b_ = list_df[k].iloc[1::2, :].round(2).values # \n",
    "  \n",
    "  a = np.concatenate((a, a_), axis=1)\n",
    "  b = np.concatenate((b, b_), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutant, cancer, leaf, synthetic\n",
    "columns = [\"none-2\", \"str-2\", \"dyn-2\", \"none-3\", \"str-3\", \"dyn-3\", \"none-4\", \"str-4\", \"dyn-4\", \"none-8\", \"str-8\", \"dyn-8\", \"none-16\", \"str-16\", \"dyn-16\", \"none-32\",\n",
    "\t\t\t\"str-32\", \"dyn-32\", \"none-64\", \"str-64\", \"dyn-64\", \"none-128\", \"str-128\", \"dyn-128\", \"none-256\", \"str-256\", \"dyn-256\", \"none-512\", \"str-512\", \"dyn-512\"] * 3\n",
    "\n",
    "row1 = [\"DGI\", \"ARGVA\", \"LVGAE\", \"VGAE\"] #, \"Greedy\"]\n",
    "row2 = [\"DGI\", \"ARGVA\", \"LVGAE\", \"VGAE\"] #, \"Greedy\"]\n",
    "row3 = [\"DGI\", \"ARGVA\", \"LVGAE\", \"VGAE\"] #, \"Greedy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace (mutant)\n",
    "\n",
    "\"\"\" a[3][4] = a.min()\n",
    "a[3][5] = a.min()\n",
    "\n",
    "b[3][61] = b.min()\n",
    "b[3][62] = b.min()\n",
    "\n",
    "c[3][61] = c.min()\n",
    "c[3][62] = c.min() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace (leaf)\n",
    "\n",
    "\"\"\" a[3][4] = a.min()\n",
    "a[3][5] = a.min()\n",
    "\n",
    "b[3][61] = b.min()\n",
    "b[3][62] = b.min() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace (synthetic)\n",
    "\n",
    "\"\"\" a[3][4] = a.min()\n",
    "a[3][5] = a.min()\n",
    "\n",
    "b[3][61] = b.min()\n",
    "b[3][62] = b.min() \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot common edges (heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutant and cancer (Heatmap)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "name = \"mutant_global\" # change\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axes = plt.subplots(3, 1, figsize=(30, 4.5))\n",
    "# Adjust layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Plot the first image\n",
    "ax0 = axes[2].imshow(a, cmap=\"Blues\", interpolation=\"none\", vmin=round(a.min()), vmax=round(a.max()))\n",
    "axes[2].set_xticks(np.arange(len(columns)), labels=columns)\n",
    "axes[2].set_yticks(np.arange(len(row1)), labels=row1)\n",
    "axes[2].set_title(\"pck1\")\n",
    "plt.setp(axes[2].get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "# axes[0].axis('off')\n",
    "cbar = fig.colorbar(ax0, ax=axes[2], ticks=[round(a.min()), round((a.min() + a.max()) / 2), round(a.max())], pad=0.005)\n",
    "cbar.set_label(\"Num. edges\")\n",
    "\n",
    "# Plot the second image\n",
    "ax1 = axes[1].imshow(b, cmap=\"Blues\", interpolation=\"none\", vmin=round(b.min()), vmax=round(b.max()))\n",
    "axes[1].set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "axes[1].set_yticks(np.arange(len(row2)), labels=row2)\n",
    "axes[1].set_title(\"zwf1\")\n",
    "# axes[1].axis('off')\n",
    "cbar = fig.colorbar(ax1, ax=axes[1], ticks=[round(b.min()), round((b.min() + b.max()) / 2), round(b.max())], pad=0.005)\n",
    "cbar.set_label(\"Num. edges\")\n",
    "\n",
    "# Plot the third image\n",
    "ax2 = axes[0].imshow(c, cmap=\"Blues\", interpolation=\"none\", vmin=round(c.min()), vmax=round(c.max()))\n",
    "axes[0].set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "axes[0].set_yticks(np.arange(len(row3)), labels=row3)\n",
    "axes[0].set_title(\"WT\")\n",
    "# axes[2].axis('off')\n",
    "cbar = fig.colorbar(ax2, ax=axes[0], ticks=[round(c.min()), round((c.min() + c.max()) / 2), round(c.max())], pad=0.005)\n",
    "cbar.set_label(\"Num. edges\")\n",
    "\n",
    "# Create a single colorbar for all subplots\n",
    "# cbar = fig.colorbar(ax2, ax=axes.ravel().tolist(), fraction=0.02, pad=0.02)\n",
    "# cbar.set_label(\"Num. of common edges\")\n",
    "\n",
    "\"\"\" cax = plt.axes((0.888, 0.11, 0.02, 0.77)) # change mutant\n",
    "# cax = plt.axes((0.735, 0.11, 0.02, 0.77)) # change cancer\n",
    "cbar = fig.colorbar(ax1, cax=cax)\n",
    "cbar.set_label(\"Common edges\") \"\"\"\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"experiments/plots/common_edges_{}.pdf\".format(name), format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leaf, sythetic (Heatmap)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "name = \"leaf_global\" # change\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axes = plt.subplots(2, 1, figsize=(30, 3))\n",
    "# Adjust layout\n",
    "# plt.tight_layout()\n",
    "\n",
    "# Plot the first image\n",
    "ax0 = axes[0].imshow(a, cmap=\"Blues\", interpolation=\"none\", vmin=round(a.min()), vmax=round(a.max()))\n",
    "axes[0].set_xticks(np.arange(len(columns)), labels=\"\")\n",
    "axes[0].set_yticks(np.arange(len(row1)), labels=row1)\n",
    "axes[0].set_title(\"new\") # phenotype1, new\n",
    "# axes[0].axis('off')\n",
    "cbar = fig.colorbar(ax0, ax=axes[0], ticks=[round(a.min()), round((a.min() + a.max()) / 2), round(a.max())], pad=0.005)\n",
    "cbar.set_label(\"Num. edges\")\n",
    "\n",
    "# Plot the third image\n",
    "ax1 = axes[1].imshow(b, cmap=\"Blues\", interpolation=\"none\", vmin=round(b.min()), vmax=round(b.max()))\n",
    "axes[1].set_xticks(np.arange(len(columns)), labels=columns)\n",
    "axes[1].set_yticks(np.arange(len(row2)), labels=row2)\n",
    "plt.setp(axes[1].get_xticklabels(), rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "axes[1].set_title(\"old\") # phenotype2, old\n",
    "# axes[1].axis('off')\n",
    "cbar = fig.colorbar(ax1, ax=axes[1], ticks=[round(b.min()), round((b.min() + b.max()) / 2), round(b.max())], pad=0.005)\n",
    "cbar.set_label(\"Num. edges\")\n",
    "\n",
    "# Create a single colorbar for all subplots\n",
    "# cbar = fig.colorbar(ax1, ax=axes.ravel().tolist(), fraction=0.02, pad=0.02, shrink=1)\n",
    "# cbar.set_label(\"Num. of common edges\")\n",
    "\n",
    "\"\"\" cax = plt.axes((0.873, 0.11, 0.02, 0.77))\n",
    "cbar = fig.colorbar(ax1, cax=cax)\n",
    "cbar.set_label(\"Common edges\") \"\"\"\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(\"experiments/plots/common_edges_{}.pdf\".format(name), format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot common edges (Line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"synthetic\" # change\n",
    "\n",
    "df_edges_count_avg1 = pd.read_csv(\"experiments/run_details/edges_avg_{}.csv\".format(dataset), index_col=0)\n",
    "df_edges_count_avg1\n",
    "\n",
    "df_edges_count_avg2 = pd.read_csv(\"experiments/run_details/edges_avg_{}_laplacian.csv\".format(dataset), index_col=0)\n",
    "df_edges_count_avg2\n",
    "\n",
    "df_edges_count_avg3 = pd.read_csv(\"experiments/run_details/edges_avg_{}_random.csv\".format(dataset), index_col=0)\n",
    "df_edges_count_avg3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df_edges_count_avg1.columns)\n",
    "columns\n",
    "\n",
    "indexes = list(df_edges_count_avg1.index)\n",
    "indexes\n",
    "\n",
    "for k in range(len(df_edges_count_avg1)):\n",
    "  print(indexes[k])\n",
    "  x = list(range(len(columns)))\n",
    "  \n",
    "  plt.subplots(figsize=(12, 5))\n",
    "  y = df_edges_count_avg1.iloc[k].values\n",
    "  plt.plot(x, y, label=\"GNN\", marker=\".\")\n",
    "  # plt.bar(x, y)\n",
    "  \n",
    "  y = df_edges_count_avg2.iloc[k].values\n",
    "  plt.plot(x, y, label=\"GNN + Laplacian\", marker=\".\")\n",
    "  # plt.bar(x, y)\n",
    "  \n",
    "  y = df_edges_count_avg3.iloc[k].values\n",
    "  plt.plot(x, y, label=\"GNN + RandomWalk\", marker=\".\")\n",
    "  # plt.bar(x, y)\n",
    "\n",
    "  plt.xticks(np.arange(len(columns)), labels=columns, rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "  plt.xlabel(\"Variation + Dimension\")\n",
    "  plt.ylabel(\"# edges\")\n",
    "  plt.legend()\n",
    "  \n",
    "  # plt.savefig(\"experiments/plots/common_edges_{}.pdf\".format(indexes[k]), format=\"pdf\", bbox_inches=\"tight\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"synthetic\" # change\n",
    "\n",
    "list_df = []\n",
    "\n",
    "df_edges_count_avg1 = pd.read_csv(\"experiments/run_details/runtimes_{}.csv\".format(dataset), index_col=0)\n",
    "list_df.append(df_edges_count_avg1)\n",
    "\n",
    "df_edges_count_avg2 = pd.read_csv(\"experiments/run_details/runtimes_{}_laplacian.csv\".format(dataset), index_col=0)\n",
    "list_df.append(df_edges_count_avg2)\n",
    "\n",
    "df_edges_count_avg3 = pd.read_csv(\"experiments/run_details/runtimes_{}_random.csv\".format(dataset), index_col=0)\n",
    "list_df.append(df_edges_count_avg3)\n",
    "\n",
    "df_edges_count_avg3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node embeddings\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "x = [\"2\", \"3\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\", \"256\", \"512\"] # change [\"3\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"]\n",
    "titles = [\"GNN\", \"GNN + Laplacian\", \"GNN + RandomWalk\"]\n",
    "\n",
    "name = \"synthetic_global\" # change\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
    "\n",
    "for d, df in enumerate(list_df):\n",
    "  df_runtimes = df.copy()\n",
    "  df_runtimes[\"Method\"] = [\"DGI\"] * 3 + [\"ARGVA\"] * 3 + [\"LVGAE\"] * 3 + [\"VGAE\"] * 3\n",
    "  df_runtimes\n",
    "  \n",
    "  z = df_runtimes.iloc[:, 2:].values\n",
    "  \n",
    "  k = 0\n",
    "  end = 10 # change 5:32, 7:128, 10: 512\n",
    "\n",
    "  for i in range(0, len(df_runtimes), 3):\n",
    "    axs[d].plot(x, z[i, :end], label=\"{}-{}\".format(df_runtimes.iloc[i, 0], df_runtimes.iloc[i, 1]), linestyle=\"-\", color=colors[k], linewidth=1)\n",
    "    axs[d].plot(x, z[i + 1, :end], label=\"{}-{}\".format(df_runtimes.iloc[i + 1, 0], df_runtimes.iloc[i + 1, 1]), linestyle=\"--\", color=colors[k], linewidth=1)\n",
    "    axs[d].plot(x, z[i + 2, :end], label=\"{}-{}\".format(df_runtimes.iloc[i + 2, 0], df_runtimes.iloc[i + 2, 1]), linestyle=\":\", color=colors[k], linewidth=1)\n",
    "    k += 1\n",
    "  axs[d].set_title(titles[d])\n",
    "  axs[d].grid(axis=\"y\")\n",
    "\n",
    "fig.tight_layout()\n",
    "axs[0].set_ylabel(\"Runtimes (sec.)\")\n",
    "axs[1].set_xlabel(\"Dimensions\")\n",
    "axs[1].legend(ncols=4, fontsize=8, loc=\"upper center\", frameon=False)\n",
    "\n",
    "plt.savefig(\"experiments/plots/runtimes_node_embeddings_{}.pdf\".format(name), format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge embeddings\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "x = [\"2\", \"3\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\", \"256\", \"512\"] # change [\"3\", \"4\", \"8\", \"16\", \"32\", \"64\", \"128\"]\n",
    "titles = [\"GNN\", \"GNN + Laplacian\", \"GNN + RandomWalk\"]\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
    "\n",
    "for d, df in enumerate(list_df):\n",
    "  df_runtimes = df.copy()\n",
    "  df_runtimes[\"Method\"] = [\"DGI\"] * 3 + [\"ARGVA\"] * 3 + [\"LVGAE\"] * 3 + [\"VGAE\"] * 3\n",
    "  df_runtimes\n",
    "  \n",
    "  z = df_runtimes.iloc[:, 2:].values\n",
    "  \n",
    "  k = 0\n",
    "  end = 10 # change 5:32, 7:128, 10: 512\n",
    "\n",
    "  for i in range(0, len(df_runtimes), 3):\n",
    "    axs[d].plot(x, z[i, end:], label=\"{}-{}\".format(df_runtimes.iloc[i, 0], df_runtimes.iloc[i, 1]), linestyle=\"-\", color=colors[k], linewidth=1)\n",
    "    axs[d].plot(x, z[i + 1, end:], label=\"{}-{}\".format(df_runtimes.iloc[i + 1, 0], df_runtimes.iloc[i + 1, 1]), linestyle=\"--\", color=colors[k], linewidth=1)\n",
    "    axs[d].plot(x, z[i + 2, end:], label=\"{}-{}\".format(df_runtimes.iloc[i + 2, 0], df_runtimes.iloc[i + 2, 1]), linestyle=\":\", color=colors[k], linewidth=1)\n",
    "    k += 1\n",
    "  axs[d].set_title(titles[d])\n",
    "  axs[d].grid(axis=\"y\")\n",
    "    \n",
    "fig.tight_layout()\n",
    "axs[0].set_ylabel(\"Runtimes (sec.)\")\n",
    "axs[1].set_xlabel(\"Dimensions\")\n",
    "axs[1].legend(ncols=4, fontsize=8, loc=\"upper center\", frameon=False)\n",
    "\n",
    "plt.savefig(\"experiments/plots/runtimes_edge_embeddings_{}.pdf\".format(name), format=\"pdf\", bbox_inches=\"tight\") # change\n",
    "plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot runtimes 1-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mutant\" # change\n",
    "\n",
    "df_edges_count_avg1 = pd.read_csv(\"experiments/run_details/runtimes_{}.csv\".format(dataset), index_col=0)\n",
    "df_edges_count_avg1\n",
    "\n",
    "df_edges_count_avg2 = pd.read_csv(\"experiments/run_details/runtimes_{}_laplacian.csv\".format(dataset), index_col=0)\n",
    "df_edges_count_avg2\n",
    "\n",
    "df_edges_count_avg3 = pd.read_csv(\"experiments/run_details/runtimes_{}_random.csv\".format(dataset), index_col=0)\n",
    "df_edges_count_avg3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(df_edges_count_avg3.iloc[:, 2:].columns)\n",
    "columns\n",
    "\n",
    "indexes = list(df_edges_count_avg3[\"Method\"].values)\n",
    "indexes\n",
    "\n",
    "for k in range(len(df_edges_count_avg1.iloc[:, 2:])):\n",
    "  print(indexes[k])\n",
    "  x = list(range(len(columns)))[:10]\n",
    "  \n",
    "  fig, axs = plt.subplots(1, 2, figsize=(16, 4))\n",
    "  # plt.subplots(figsize=(12, 5))\n",
    "  y = df_edges_count_avg1.iloc[k, 2:12].values\n",
    "  axs[0].plot(x, y, label=\"GNN\", marker=\".\")\n",
    "  \n",
    "  y = df_edges_count_avg2.iloc[k, 2:12].values\n",
    "  axs[0].plot(x, y, label=\"GNN + Laplacian\", marker=\".\")\n",
    "  \n",
    "  y = df_edges_count_avg3.iloc[k, 2:12].values\n",
    "  axs[0].plot(x, y, label=\"GNN + RandomWalk\", marker=\".\")\n",
    "  \n",
    "  axs[0].set_xticks(np.arange(len(columns) / 2), labels=columns[:10], rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "  \n",
    "  # x = list(range(len(columns)))[10:]\n",
    "  \n",
    "  y = df_edges_count_avg1.iloc[k, 12:].values\n",
    "  axs[1].plot(x, y, label=\"GNN\", marker=\".\")\n",
    "  # plt.bar(x, y)\n",
    "    \n",
    "  y = df_edges_count_avg2.iloc[k, 12:].values\n",
    "  axs[1].plot(x, y, label=\"GNN + Laplacian\", marker=\".\")\n",
    "  # plt.bar(x, y)\n",
    "  \n",
    "  y = df_edges_count_avg3.iloc[k, 12:].values\n",
    "  axs[1].plot(x, y, label=\"GNN + RandomWalk\", marker=\".\")\n",
    "  # plt.bar(x, y)\n",
    "\n",
    "  axs[1].set_xticks(np.arange(len(columns) / 2), labels=columns[10:], rotation=60, ha=\"right\", rotation_mode=\"anchor\")\n",
    "  # plt.xlabel(\"Dimensions\")\n",
    "  # plt.ylabel(\"Runtimes (sec.)\")\n",
    "  plt.legend()\n",
    "  # plt.savefig(\"experiments/plots/common_edges_{}.pdf\".format(indexes[k]), format=\"pdf\", bbox_inches=\"tight\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-smoothing measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"exp1251\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "\n",
    "print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "control = params[\"control\"]\n",
    "print(\"Control:\\t\", control)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_3d(df_embeddings, labels, reduction=\"pca\", embedding=\"node\", title=\"\", title_legend=\"\", save=False):\n",
    "\t# print(df_embeddings)\n",
    "\t# print(labels)\n",
    "\tif df_embeddings.shape[1] > 3:\n",
    "\t\tif reduction == \"pca\":\n",
    "\t\t\tdf_embeddings_red = PCA(n_components=3).fit_transform(df_embeddings)\n",
    "\t\telif reduction == \"tsne\":\n",
    "\t\t\tdf_embeddings_red = TSNE(n_components=3).fit_transform(df_embeddings)\n",
    "\t\telif reduction == \"umap\":\n",
    "\t\t\tdf_embeddings_red = umap.UMAP().fit_transform(df_embeddings)\n",
    "\telse:\n",
    "\t\tdf_embeddings_red = df_embeddings.values\n",
    "\t\n",
    "\tfig = plt.figure(figsize=(6, 6))\n",
    "\tax = fig.add_subplot(projection=\"3d\")\n",
    "\t\n",
    "\tdf_embeddings = pd.DataFrame(df_embeddings_red)\n",
    "\tdf_embeddings[\"labels\"] = labels.values\n",
    "\t\n",
    "\tunique_labels = np.unique(labels)\n",
    "\tfor i, label in enumerate(unique_labels):\n",
    "\t\tdf_embeddings_filter = df_embeddings[df_embeddings[\"labels\"] == label]\n",
    "\n",
    "\t\tx = df_embeddings_filter.iloc[:, 0]\n",
    "\t\ty = df_embeddings_filter.iloc[:, 1]\n",
    "\t\tz = df_embeddings_filter.iloc[:, 2]\n",
    "\t\t\n",
    "\t\t# new_cmap = matplotlib.colors.ListedColormap(plt.cm.tab10.colors[i: i + 1])\n",
    "\t\tif embedding == \"node\":\n",
    "\t\t\tcolor = matplotlib.colors.ListedColormap(plt.cm.Dark2.colors[i: i + 1]).colors[0]\n",
    "\t\t\t# points = ax.scatter(x, y, z, s=100, c=labels, alpha=0.5, cmap=new_cmap , marker=\".\") # , edgecolors=\"black\", linewidth=0.5)\n",
    "\t\t\tpoints = ax.scatter(x, y, z, s=100, alpha=0.5, color=color, marker=\".\", label=\"Br{}\".format(label + 1))\n",
    "\t\telif embedding == \"edge\":\n",
    "\t\t\tcolor = matplotlib.colors.ListedColormap(plt.cm.Dark2.colors[i: i + 1]).colors[0]\n",
    "\t\t\t# points = ax.scatter(x, y, z, s=100, c=labels, alpha=0.5, cmap=new_cmap , marker=\".\") # , edgecolors=\"black\", linewidth=0.5)\n",
    "\t\t\tpoints = ax.scatter(x, y, z, s=100, alpha=0.5, color=color, marker=\".\", label=\"Br{}\".format(label + 1))\n",
    "\t\telif embedding == \"outlier\":\n",
    "\t\t\t# cmap = matplotlib.colormaps.get_cmap(\"coolwarm\", len(unique_labels))\n",
    "\t\t\tcolors = plt.get_cmap(\"coolwarm\")(np.linspace(0, 1, len(unique_labels)))\n",
    "\t\t\tpoints = ax.scatter(x, y, z, s=100, alpha=0.5, c=[colors[label]], marker=\".\", label=[\"inliers\", \"outliers\"][label]) #, edgecolors=\"black\", linewidth=0.5)\n",
    "\t\n",
    "\t# ax.set_xlabel(\"X\")\n",
    "\t# ax.set_ylabel(\"Y\")\n",
    "\t# ax.set_zlabel(\"Z\")\n",
    "\tif not save:\n",
    "\t\t\"\"\" plt.title(title)\n",
    "\t\tplt.legend(title=title_legend, ncol=1, loc=0, bbox_to_anchor=(1, 0.95)) \"\"\"\n",
    "\t\t# fig.colorbar(points, ax=ax, shrink=0.4, aspect=8) # bar\n",
    "\t\t# ax.legend([\"Biological rep.: {}\".format(subgroup) for subgroup in np.unique(labels)])\n",
    "\t\t# print(*points.legend_elements())\n",
    "\t\t# plt.legend(*points.legend_elements(), bbox_to_anchor=(1.05, 1), loc=2)\n",
    "\tif save:\n",
    "\t\t# plt.legend(title=title_legend, ncol=1, loc=0, bbox_to_anchor=(1, 0.95)) # ncol=len(unique_labels)\n",
    "\t\tplt.savefig(\"experiments/plots/{}.pdf\".format(title), format=\"pdf\", bbox_inches=\"tight\") # change    \n",
    "\tplt.show()\n",
    "\treturn ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "#releated paper:(AAAI2020) Measuring and Relieving the Over-smoothing Problem for Graph Neural Networks from the Topological View.\n",
    "#https://aaai.org/ojs/index.php/AAAI/article/view/5747\n",
    "\n",
    "#the numpy version for mad (Be able to compute quickly)\n",
    "#in_arr:[node_num * hidden_dim], the node feature matrix;\n",
    "#mask_arr: [node_num * node_num], the mask matrix of the target raltion;\n",
    "#target_idx = [1,2,3...n], the nodes idx for which we calculate the mad value;\n",
    "def mad_value(in_arr, mask_arr, distance_metric='cosine', digt_num=4, target_idx =None):\n",
    "    dist_arr = pairwise_distances(in_arr, in_arr, metric=distance_metric)\n",
    "    \n",
    "    mask_dist = np.multiply(dist_arr,mask_arr)\n",
    "\n",
    "    divide_arr = (mask_dist != 0).sum(1) + 1e-8\n",
    "\n",
    "    node_dist = mask_dist.sum(1) / divide_arr\n",
    "\n",
    "    if target_idx.any()==None:\n",
    "        mad = np.mean(node_dist)\n",
    "    else:\n",
    "        node_dist = np.multiply(node_dist,target_idx)\n",
    "        mad = node_dist.sum()/((node_dist!=0).sum()+1e-8)\n",
    "\n",
    "    mad = round(mad, digt_num)\n",
    "\n",
    "    return mad\n",
    "\n",
    "#the tensor version for mad_gap (Be able to transfer gradients)\n",
    "#intensor: [node_num * hidden_dim], the node feature matrix;\n",
    "#neb_mask,rmt_mask:[node_num * node_num], the mask matrices of the neighbor and remote raltion;\n",
    "#target_idx = [1,2,3...n], the nodes idx for which we calculate the mad_gap value;\n",
    "def mad_gap_regularizer(intensor,neb_mask,rmt_mask,target_idx):\n",
    "    node_num,feat_num = intensor.size()\n",
    "\n",
    "    input1 = intensor.expand(node_num,node_num,feat_num)\n",
    "    input2 = input1.transpose(0,1)\n",
    "\n",
    "    input1 = input1.contiguous().view(-1,feat_num)\n",
    "    input2 = input2.contiguous().view(-1,feat_num)\n",
    "\n",
    "    simi_tensor = F.cosine_similarity(input1,input2, dim=1, eps=1e-8).view(node_num,node_num)\n",
    "    dist_tensor = 1 - simi_tensor\n",
    "\n",
    "    neb_dist = torch.mul(dist_tensor,neb_mask)\n",
    "    rmt_dist = torch.mul(dist_tensor,rmt_mask)\n",
    "    \n",
    "    divide_neb = (neb_dist!=0).sum(1).type(torch.FloatTensor).cuda() + 1e-8\n",
    "    divide_rmt = (rmt_dist!=0).sum(1).type(torch.FloatTensor).cuda() + 1e-8\n",
    "\n",
    "    neb_mean_list = neb_dist.sum(1) / divide_neb\n",
    "    rmt_mean_list = rmt_dist.sum(1) / divide_rmt\n",
    "\n",
    "    neb_mad = torch.mean(neb_mean_list[target_idx])\n",
    "    rmt_mad = torch.mean(rmt_mean_list[target_idx])\n",
    "\n",
    "    mad_gap = rmt_mad - neb_mad\n",
    "\n",
    "    return mad_gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1 # change\n",
    "save = True # change\n",
    "\n",
    "for e in [1251]: # change, experiment\n",
    "\texp = \"exp\" + str(e)\n",
    "\tfor method in methods[:]: # change\n",
    "\t\tfor group_id in groups_id[:]: # change\n",
    "\t\t\tfor data_variation in data_variations: # change\n",
    "\t\t\t\tdf_node_embeddings_concat = pd.DataFrame()\n",
    "\t\t\t\tif data_variation == \"none\":\n",
    "\t\t\t\t\tk = 0\n",
    "\t\t\t\t\tfor subgroup_id in subgroups_id[group_id]:\n",
    "\t\t\t\t\t\tprint(exp, method, group_id, subgroup_id, iteration)\n",
    "\t\t\t\t\t\tdf_node_embeddings = pd.read_csv(\"experiments/output/{}/node_embeddings/node-embeddings_{}_{}_{}_{}.csv\".format(exp, method, group_id, subgroup_id, iteration), index_col=0)\n",
    "\t\t\t\t\t\t\n",
    "\t\t\t\t\t\tdf_node_embeddings[\"subgroup\"] = [k] * len(df_node_embeddings)\n",
    "\t\t\t\t\t\tdf_node_embeddings_concat = pd.concat([df_node_embeddings_concat, df_node_embeddings])\n",
    "\t\t\t\t\t\tk += 1\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprint(exp, method, group_id, data_variation, iteration)\n",
    "\t\t\t\t\tdf_nodes = pd.read_csv(\"experiments/output/{}/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(exp, group_id, data_variation), index_col=0, usecols=[0, 1])\n",
    "\t\t\t\t\tdf_nodes[\"subgroup\"] = df_nodes[\"id\"].apply(lambda x: ord(x[0]) - 65)\n",
    "\n",
    "\t\t\t\t\tdf_node_embeddings = pd.read_csv(\"experiments/output/{}/node_embeddings/node-embeddings_{}_{}_{}_{}.csv\".format(exp, method, group_id, data_variation, iteration), index_col=0)\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tdf_node_embeddings[\"subgroup\"] = df_nodes[\"subgroup\"]\n",
    "\t\t\t\t\tdf_node_embeddings_concat = pd.concat([df_node_embeddings_concat, df_node_embeddings])\n",
    "\n",
    "\t\t\t\t# calculate MAD\n",
    "\t\t\t\tfor g in np.unique(df_node_embeddings_concat.iloc[:, -1]):\n",
    "\t\t\t\t\tdf_temp = df_node_embeddings_concat[df_node_embeddings_concat[\"subgroup\"] == g].iloc[:, :-1]\n",
    "\t\t\t\t\tmad = mad_value(df_temp.values, np.full((len(df_temp), len(df_temp)), True), distance_metric='cosine', digt_num=4, target_idx=np.arange(len(df_temp)))\n",
    "\t\t\t\t\tprint(g, mad)\n",
    "\t\t\t\tplot_embedding_3d(df_node_embeddings_concat.iloc[:, :-1], df_node_embeddings_concat.iloc[:, -1],\n",
    "\t\t\t\t\t\t\t\t\treduction=\"pca\", embedding=\"node\", title=\"node-embeddings_{}-{}-{}-{}\".format(exp, method, group_id, data_variation), title_legend=\"\", save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking of nodes/edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"exp1006\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "controls = params[\"controls\"]\n",
    "print(\"Control:\\t\", controls)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df_nodes = pd.read_csv(\"experiments/output/{}/preprocessing/graphs_data/nodes_data_{}_{}.csv\".format(exp, group_id, data_variations[0]))\n",
    "dict_id = dict(zip(df_nodes[\"idx\"], df_nodes[\"id\"]))\n",
    "print(dict_id)\n",
    "\n",
    "df_nodes \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_raw = pd.read_csv(\"experiments/input/{}_raw.csv\".format(exp), index_col=0)\n",
    "df_join_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find by Alignment ID\n",
    "\n",
    "n1_id = 0\n",
    "n2_id = 1\n",
    "\n",
    "name1 = df_join_raw.loc[n1_id, \"Metabolite name\"]\n",
    "name2 = df_join_raw.loc[n2_id, \"Metabolite name\"]\n",
    "print(\"INPUT\")\n",
    "print(n1_id, name1)\n",
    "print(n2_id, name2)\n",
    "print()\n",
    "\n",
    "# Correlations\n",
    "print(\"CORRELATIONS\")\n",
    "for group_id in groups_id:\n",
    "    for subgroup_id in subgroups_id[group_id]:\n",
    "        df_corr = pd.read_csv(\"experiments/output/{}/correlations/correlations_{}_{}.csv\".format(exp, group_id, subgroup_id), index_col=0)\n",
    "        \n",
    "        corr = df_corr.loc[n1_id, str(n2_id)]\n",
    "        print(group_id, subgroup_id, corr)\n",
    "print()\n",
    "df_corr\n",
    "\n",
    "# Edges list\n",
    "print(\"EDGES LIST\")\n",
    "for group_id in groups_id:\n",
    "    for subgroup_id in subgroups_id[group_id]:\n",
    "        df_edges = pd.read_csv(\"experiments/output/{}/preprocessing/edges/edges_{}_{}.csv\".format(exp, group_id, subgroup_id))\n",
    "        \n",
    "        df_temp = df_edges[\n",
    "            ((df_edges[\"source\"] == n1_id) & (df_edges[\"target\"] == n2_id)) |\n",
    "            ((df_edges[\"source\"] == n2_id) & (df_edges[\"target\"] == n1_id))\n",
    "            ]\n",
    "        df_temp\n",
    "        print(group_id, subgroup_id, df_temp[\"weight\"].values)\n",
    "print()\n",
    "df_edges\n",
    "\n",
    "# Commond edges\n",
    "# before new partial correlatios\n",
    "f = \"f1\"\n",
    "print(\"COMMON EDGES\")\n",
    "print(\"Before new partial correlations\")\n",
    "for group_id in groups_id:\n",
    "    df_edges = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}_{}_1.csv\".format(exp, f, methods[0], group_id, data_variations[0]))\n",
    "    \n",
    "    df_temp = df_edges[\n",
    "        ((df_edges[\"source\"] == n1_id) & (df_edges[\"target\"] == n2_id)) |\n",
    "        ((df_edges[\"source\"] == n2_id) & (df_edges[\"target\"] == n1_id))\n",
    "        ]\n",
    "    df_temp\n",
    "    print(group_id, df_temp.values)\n",
    "print()\n",
    "df_edges\n",
    "\n",
    "# with all new partial correlations\n",
    "print(\"With all new partial correlations\")\n",
    "for group_id in groups_id:\n",
    "    df_edges = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}_{}_all.csv\".format(exp, f, methods[0], group_id, data_variations[0]))\n",
    "    \n",
    "    df_temp = df_edges[\n",
    "        ((df_edges[\"source\"] == n1_id) & (df_edges[\"target\"] == n2_id)) |\n",
    "        ((df_edges[\"source\"] == n2_id) & (df_edges[\"target\"] == n1_id))\n",
    "        ]\n",
    "    df_temp\n",
    "    print(group_id, df_temp[\"weight\"].values)\n",
    "print()\n",
    "df_edges\n",
    "\n",
    "# with filter (th_corr) on new partial correlations\n",
    "print(\"With filter (th_corr) on new partial correlations\")\n",
    "for group_id in groups_id:\n",
    "    df_edges = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}_{}.csv\".format(exp, f, methods[0], group_id, data_variations[0]))\n",
    "    \n",
    "    df_temp = df_edges[\n",
    "        ((df_edges[\"source\"] == n1_id) & (df_edges[\"target\"] == n2_id)) |\n",
    "        ((df_edges[\"source\"] == n2_id) & (df_edges[\"target\"] == n1_id))\n",
    "        ]\n",
    "    df_temp\n",
    "    print(group_id, df_temp[\"weight\"].values)\n",
    "print()\n",
    "# df_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get filter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = \"exp402\"\n",
    "file = open(\"experiments/output/{}/parameters.json\".format(exp))\n",
    "params = json.load(file)\n",
    "\n",
    "exp = params[\"exp\"]\n",
    "print(\"Exp:\\t\\t\", exp)\n",
    "\n",
    "methods = params[\"methods\"]\n",
    "print(\"Methods:\\t\", methods)\n",
    "\n",
    "data_variations = params[\"data_variations\"]\n",
    "print(\"Data variations:\", data_variations)\n",
    "\n",
    "controls = params[\"controls\"]\n",
    "print(\"Control:\\t\", controls)\n",
    "\n",
    "groups_id = params[\"groups_id\"]\n",
    "print(\"Groups id:\\t\", groups_id)\n",
    "\n",
    "subgroups_id = params[\"subgroups_id\"]\n",
    "print(\"Subgroups id:\\t\", subgroups_id)\n",
    "\n",
    "groups = params[\"groups\"]\n",
    "print(\"Groups:\\t\\t\", groups)\n",
    "\n",
    "f = \"f1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read raw data\n",
    "\n",
    "df_join_raw = pd.read_csv(\"experiments/input/{}_raw.csv\".format(exp), index_col=0)\n",
    "df_join_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_raw_data = set(list(df_join_raw.index))\n",
    "print(len(nodes_raw_data), nodes_raw_data)\n",
    "list_common = []\n",
    "\n",
    "for group_id in groups_id:\n",
    "    \n",
    "    df_edges_filter_weight_filter = pd.read_csv(\"experiments/output/{}/common_edges/common_edges_{}_{}_{}_{}.csv\".format(exp, f, method, group_id, data_variation))\n",
    "    df_edges_filter_weight_filter\n",
    "    \n",
    "    nodes = set(np.unique(df_edges_filter_weight_filter.iloc[:, [0, 1]].values.flatten()))\n",
    "    # list_common.append([nodes]) # common, n-common\n",
    "    df_temp = pd.DataFrame(nodes, columns=[group_id])\n",
    "    df_temp.to_csv(\"z_{}.csv\".format(group_id), index=False)\n",
    "print(list_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges_filter_weight_filter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta_net_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
